{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhOdxOgxBD9a"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1)\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "WI4ZgR6UBMXb",
    "outputId": "c3cb7ae0-0512-4352-d57a-bfc9e0bf25f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4ad309f2-4a2a-477c-8a9a-479c09cc5599\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th>omega_x</th>\n",
       "      <th>omega_y</th>\n",
       "      <th>omega</th>\n",
       "      <th>pr_wtr</th>\n",
       "      <th>rhum_x</th>\n",
       "      <th>rhum_y</th>\n",
       "      <th>rhum</th>\n",
       "      <th>...</th>\n",
       "      <th>tmp_x</th>\n",
       "      <th>tmp_y</th>\n",
       "      <th>tmp</th>\n",
       "      <th>uwnd_x</th>\n",
       "      <th>uwnd_y</th>\n",
       "      <th>uwnd</th>\n",
       "      <th>vwnd_x</th>\n",
       "      <th>vwnd_y</th>\n",
       "      <th>vwnd</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>0.14300</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>5.60</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>40.75</td>\n",
       "      <td>...</td>\n",
       "      <td>296.8</td>\n",
       "      <td>282.67500</td>\n",
       "      <td>296.725</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.275001</td>\n",
       "      <td>-2.599999</td>\n",
       "      <td>-6.600</td>\n",
       "      <td>-3.925</td>\n",
       "      <td>-3.200000</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.02450</td>\n",
       "      <td>0.06525</td>\n",
       "      <td>8.40</td>\n",
       "      <td>20.50</td>\n",
       "      <td>19.00</td>\n",
       "      <td>34.50</td>\n",
       "      <td>...</td>\n",
       "      <td>296.8</td>\n",
       "      <td>284.15000</td>\n",
       "      <td>296.700</td>\n",
       "      <td>12.125002</td>\n",
       "      <td>5.850001</td>\n",
       "      <td>-1.749999</td>\n",
       "      <td>-5.075</td>\n",
       "      <td>-3.975</td>\n",
       "      <td>-2.200000</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1/3/2015</td>\n",
       "      <td>0.18125</td>\n",
       "      <td>0.16325</td>\n",
       "      <td>0.10375</td>\n",
       "      <td>11.35</td>\n",
       "      <td>29.50</td>\n",
       "      <td>46.50</td>\n",
       "      <td>41.00</td>\n",
       "      <td>...</td>\n",
       "      <td>296.8</td>\n",
       "      <td>284.67500</td>\n",
       "      <td>296.600</td>\n",
       "      <td>26.575000</td>\n",
       "      <td>10.875000</td>\n",
       "      <td>0.775001</td>\n",
       "      <td>-13.925</td>\n",
       "      <td>-5.725</td>\n",
       "      <td>-0.874999</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1/4/2015</td>\n",
       "      <td>0.12350</td>\n",
       "      <td>0.07725</td>\n",
       "      <td>-0.09000</td>\n",
       "      <td>12.40</td>\n",
       "      <td>36.50</td>\n",
       "      <td>38.75</td>\n",
       "      <td>40.50</td>\n",
       "      <td>...</td>\n",
       "      <td>296.8</td>\n",
       "      <td>285.15002</td>\n",
       "      <td>296.550</td>\n",
       "      <td>35.949997</td>\n",
       "      <td>18.375000</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>-20.400</td>\n",
       "      <td>-6.050</td>\n",
       "      <td>2.925002</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>-0.04575</td>\n",
       "      <td>0.04225</td>\n",
       "      <td>0.01700</td>\n",
       "      <td>11.25</td>\n",
       "      <td>20.75</td>\n",
       "      <td>22.25</td>\n",
       "      <td>38.75</td>\n",
       "      <td>...</td>\n",
       "      <td>296.8</td>\n",
       "      <td>285.75000</td>\n",
       "      <td>296.500</td>\n",
       "      <td>40.700000</td>\n",
       "      <td>17.400002</td>\n",
       "      <td>3.175001</td>\n",
       "      <td>-7.900</td>\n",
       "      <td>-6.550</td>\n",
       "      <td>1.575000</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ad309f2-4a2a-477c-8a9a-479c09cc5599')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4ad309f2-4a2a-477c-8a9a-479c09cc5599 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4ad309f2-4a2a-477c-8a9a-479c09cc5599');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    lat   lon      time  omega_x  omega_y    omega  pr_wtr  rhum_x  rhum_y  \\\n",
       "0  30.0  70.0  1/1/2015  0.14300  0.10950  0.12600    5.60    1.75    0.75   \n",
       "1  30.0  70.0  1/2/2015  0.02925  0.02450  0.06525    8.40   20.50   19.00   \n",
       "2  30.0  70.0  1/3/2015  0.18125  0.16325  0.10375   11.35   29.50   46.50   \n",
       "3  30.0  70.0  1/4/2015  0.12350  0.07725 -0.09000   12.40   36.50   38.75   \n",
       "4  30.0  70.0  1/5/2015 -0.04575  0.04225  0.01700   11.25   20.75   22.25   \n",
       "\n",
       "    rhum  ...  tmp_x      tmp_y      tmp     uwnd_x     uwnd_y      uwnd  \\\n",
       "0  40.75  ...  296.8  282.67500  296.725   4.350000   1.275001 -2.599999   \n",
       "1  34.50  ...  296.8  284.15000  296.700  12.125002   5.850001 -1.749999   \n",
       "2  41.00  ...  296.8  284.67500  296.600  26.575000  10.875000  0.775001   \n",
       "3  40.50  ...  296.8  285.15002  296.550  35.949997  18.375000  1.325000   \n",
       "4  38.75  ...  296.8  285.75000  296.500  40.700000  17.400002  3.175001   \n",
       "\n",
       "   vwnd_x  vwnd_y      vwnd    rain  \n",
       "0  -6.600  -3.925 -3.200000 -9999.0  \n",
       "1  -5.075  -3.975 -2.200000 -9999.0  \n",
       "2 -13.925  -5.725 -0.874999 -9999.0  \n",
       "3 -20.400  -6.050  2.925002 -9999.0  \n",
       "4  -7.900  -6.550  1.575000 -9999.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.DataFrame(pd.read_csv(\"https://raw.githubusercontent.com/Tareq-BD/ECGR-5105/main/Weather%20Dataset.csv\"))\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WPRnUUGB10k",
    "outputId": "fd12ee47-3f48-455e-b5ad-6a647677bb20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17902"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(weather)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDgICM7_CA8v",
    "outputId": "a638158f-4734-4028-a1d7-7d6ff79b578a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17902, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YIasLshCEYV",
    "outputId": "58f739ee-376d-4e42-9503-06449ab95062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12531, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(weather, train_size = 0.7, test_size = 0.3)\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osB6A3NGCK5_",
    "outputId": "cd1c39d4-4a04-4d55-d55e-0382132b8c79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5371, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "HbmPRj3_CNMX",
    "outputId": "b453f860-6516-48eb-fd25-6e744704048f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cd91e52b-5200-4ad8-9239-f53b728f8b5e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>omega_x</th>\n",
       "      <th>omega_y</th>\n",
       "      <th>omega</th>\n",
       "      <th>pr_wtr</th>\n",
       "      <th>rhum_x</th>\n",
       "      <th>rhum_y</th>\n",
       "      <th>rhum</th>\n",
       "      <th>slp</th>\n",
       "      <th>tmp_x</th>\n",
       "      <th>tmp_y</th>\n",
       "      <th>tmp</th>\n",
       "      <th>uwnd_x</th>\n",
       "      <th>uwnd_y</th>\n",
       "      <th>uwnd</th>\n",
       "      <th>vwnd_x</th>\n",
       "      <th>vwnd_y</th>\n",
       "      <th>vwnd</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14064</th>\n",
       "      <td>25.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>0.09825</td>\n",
       "      <td>0.07725</td>\n",
       "      <td>-0.00475</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>23.75</td>\n",
       "      <td>19.00</td>\n",
       "      <td>100687.5</td>\n",
       "      <td>297.6</td>\n",
       "      <td>305.35000</td>\n",
       "      <td>296.80000</td>\n",
       "      <td>-0.699998</td>\n",
       "      <td>1.650001</td>\n",
       "      <td>5.750001</td>\n",
       "      <td>-11.474999</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>0.475002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>27.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.04725</td>\n",
       "      <td>-0.04525</td>\n",
       "      <td>0.01625</td>\n",
       "      <td>12.425001</td>\n",
       "      <td>16.25</td>\n",
       "      <td>34.50</td>\n",
       "      <td>36.75</td>\n",
       "      <td>101485.0</td>\n",
       "      <td>296.2</td>\n",
       "      <td>287.55000</td>\n",
       "      <td>294.30000</td>\n",
       "      <td>50.525000</td>\n",
       "      <td>26.150002</td>\n",
       "      <td>1.925002</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2.275001</td>\n",
       "      <td>-1.199999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>27.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>0.07375</td>\n",
       "      <td>0.07950</td>\n",
       "      <td>0.01075</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>13.25</td>\n",
       "      <td>56.25</td>\n",
       "      <td>53.50</td>\n",
       "      <td>99560.0</td>\n",
       "      <td>296.7</td>\n",
       "      <td>309.44998</td>\n",
       "      <td>299.07498</td>\n",
       "      <td>-0.299999</td>\n",
       "      <td>-0.799998</td>\n",
       "      <td>1.675002</td>\n",
       "      <td>-6.825000</td>\n",
       "      <td>-7.074999</td>\n",
       "      <td>5.825000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.09225</td>\n",
       "      <td>0.02700</td>\n",
       "      <td>-0.05300</td>\n",
       "      <td>28.675000</td>\n",
       "      <td>13.00</td>\n",
       "      <td>40.25</td>\n",
       "      <td>27.25</td>\n",
       "      <td>100165.0</td>\n",
       "      <td>297.6</td>\n",
       "      <td>308.20000</td>\n",
       "      <td>298.10000</td>\n",
       "      <td>3.875001</td>\n",
       "      <td>5.525001</td>\n",
       "      <td>1.425002</td>\n",
       "      <td>-6.375000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.01250</td>\n",
       "      <td>-0.19925</td>\n",
       "      <td>-0.12800</td>\n",
       "      <td>34.350000</td>\n",
       "      <td>17.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>99677.5</td>\n",
       "      <td>297.6</td>\n",
       "      <td>311.44998</td>\n",
       "      <td>297.80000</td>\n",
       "      <td>10.025000</td>\n",
       "      <td>7.350001</td>\n",
       "      <td>3.650001</td>\n",
       "      <td>1.475000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd91e52b-5200-4ad8-9239-f53b728f8b5e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cd91e52b-5200-4ad8-9239-f53b728f8b5e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cd91e52b-5200-4ad8-9239-f53b728f8b5e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        lat   lon  omega_x  omega_y    omega     pr_wtr  rhum_x  rhum_y  \\\n",
       "14064  25.0  72.5  0.09825  0.07725 -0.00475  17.400000    3.50   23.75   \n",
       "8981   27.5  75.0  0.04725 -0.04525  0.01625  12.425001   16.25   34.50   \n",
       "7703   27.5  72.5  0.07375  0.07950  0.01075  49.600000   13.25   56.25   \n",
       "3731   30.0  75.0  0.09225  0.02700 -0.05300  28.675000   13.00   40.25   \n",
       "3370   30.0  75.0 -0.01250 -0.19925 -0.12800  34.350000   17.50   54.00   \n",
       "\n",
       "        rhum       slp  tmp_x      tmp_y        tmp     uwnd_x     uwnd_y  \\\n",
       "14064  19.00  100687.5  297.6  305.35000  296.80000  -0.699998   1.650001   \n",
       "8981   36.75  101485.0  296.2  287.55000  294.30000  50.525000  26.150002   \n",
       "7703   53.50   99560.0  296.7  309.44998  299.07498  -0.299999  -0.799998   \n",
       "3731   27.25  100165.0  297.6  308.20000  298.10000   3.875001   5.525001   \n",
       "3370   28.00   99677.5  297.6  311.44998  297.80000  10.025000   7.350001   \n",
       "\n",
       "           uwnd     vwnd_x    vwnd_y      vwnd  rain  \n",
       "14064  5.750001 -11.474999 -3.300000  0.475002   0.0  \n",
       "8981   1.925002   3.800000  2.275001 -1.199999   0.0  \n",
       "7703   1.675002  -6.825000 -7.074999  5.825000   0.0  \n",
       "3731   1.425002  -6.375000 -4.500000  1.675000   0.0  \n",
       "3370   3.650001   1.475000  0.650000  2.075000   0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vars = ['lat', 'lon','omega_x', 'omega_y', 'omega', 'pr_wtr', 'rhum_x','rhum_y', 'rhum', 'slp', 'tmp_x', 'tmp_y', 'tmp','uwnd_x', 'uwnd_y', 'uwnd', 'vwnd_x', 'vwnd_y', 'vwnd','rain']\n",
    "df_Newtrain = df_train[num_vars]\n",
    "df_Newtest = df_test[num_vars]\n",
    "df_Newtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbiSmCUvCWnu",
    "outputId": "73a52e31-abaa-41f4-9806-be7cafe33722"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12531, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Newtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "id": "qSPm-LV9CY_p",
    "outputId": "cc12b905-d95d-45c4-ca06-6dc972d5a91a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-612fa45c-3fa6-4546-8370-00d05cead04f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>omega_x</th>\n",
       "      <th>omega_y</th>\n",
       "      <th>omega</th>\n",
       "      <th>pr_wtr</th>\n",
       "      <th>rhum_x</th>\n",
       "      <th>rhum_y</th>\n",
       "      <th>rhum</th>\n",
       "      <th>slp</th>\n",
       "      <th>tmp_x</th>\n",
       "      <th>tmp_y</th>\n",
       "      <th>tmp</th>\n",
       "      <th>uwnd_x</th>\n",
       "      <th>uwnd_y</th>\n",
       "      <th>uwnd</th>\n",
       "      <th>vwnd_x</th>\n",
       "      <th>vwnd_y</th>\n",
       "      <th>vwnd</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14064</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.608827</td>\n",
       "      <td>0.732563</td>\n",
       "      <td>0.621372</td>\n",
       "      <td>0.233948</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.502604</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.767097</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.234103</td>\n",
       "      <td>0.401093</td>\n",
       "      <td>0.651952</td>\n",
       "      <td>0.326577</td>\n",
       "      <td>0.361812</td>\n",
       "      <td>0.458281</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.561440</td>\n",
       "      <td>0.625763</td>\n",
       "      <td>0.643536</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>0.710286</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.307742</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.944525</td>\n",
       "      <td>0.936612</td>\n",
       "      <td>0.522071</td>\n",
       "      <td>0.560229</td>\n",
       "      <td>0.506149</td>\n",
       "      <td>0.374844</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.586063</td>\n",
       "      <td>0.734525</td>\n",
       "      <td>0.637731</td>\n",
       "      <td>0.673839</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.208984</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.872903</td>\n",
       "      <td>0.624999</td>\n",
       "      <td>0.239650</td>\n",
       "      <td>0.347541</td>\n",
       "      <td>0.513582</td>\n",
       "      <td>0.397706</td>\n",
       "      <td>0.264078</td>\n",
       "      <td>0.724782</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.603252</td>\n",
       "      <td>0.688753</td>\n",
       "      <td>0.570449</td>\n",
       "      <td>0.387978</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.366536</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.840645</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.297552</td>\n",
       "      <td>0.485792</td>\n",
       "      <td>0.505093</td>\n",
       "      <td>0.404589</td>\n",
       "      <td>0.330744</td>\n",
       "      <td>0.518057</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.505923</td>\n",
       "      <td>0.491500</td>\n",
       "      <td>0.491293</td>\n",
       "      <td>0.465505</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.924516</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.382844</td>\n",
       "      <td>0.525683</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.524665</td>\n",
       "      <td>0.464078</td>\n",
       "      <td>0.537983</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476887</td>\n",
       "      <td>0.644289</td>\n",
       "      <td>0.586016</td>\n",
       "      <td>0.474044</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.5675</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776774</td>\n",
       "      <td>0.559701</td>\n",
       "      <td>0.441439</td>\n",
       "      <td>0.492896</td>\n",
       "      <td>0.668930</td>\n",
       "      <td>0.585851</td>\n",
       "      <td>0.530744</td>\n",
       "      <td>0.582814</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489895</td>\n",
       "      <td>0.680471</td>\n",
       "      <td>0.658575</td>\n",
       "      <td>0.408811</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.494792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.295472</td>\n",
       "      <td>0.346995</td>\n",
       "      <td>0.578098</td>\n",
       "      <td>0.583174</td>\n",
       "      <td>0.508091</td>\n",
       "      <td>0.473225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8047</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.613705</td>\n",
       "      <td>0.728204</td>\n",
       "      <td>0.553298</td>\n",
       "      <td>0.514003</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.4275</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.821290</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.426531</td>\n",
       "      <td>0.445355</td>\n",
       "      <td>0.507640</td>\n",
       "      <td>0.433270</td>\n",
       "      <td>0.363107</td>\n",
       "      <td>0.509340</td>\n",
       "      <td>0.968506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14446</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.603252</td>\n",
       "      <td>0.676330</td>\n",
       "      <td>0.540106</td>\n",
       "      <td>0.348019</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>0.391927</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.828387</td>\n",
       "      <td>0.468284</td>\n",
       "      <td>0.305527</td>\n",
       "      <td>0.403279</td>\n",
       "      <td>0.679117</td>\n",
       "      <td>0.235564</td>\n",
       "      <td>0.325566</td>\n",
       "      <td>0.377335</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.594890</td>\n",
       "      <td>0.657367</td>\n",
       "      <td>0.632718</td>\n",
       "      <td>0.175546</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>0.673828</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>0.483210</td>\n",
       "      <td>0.486513</td>\n",
       "      <td>0.484153</td>\n",
       "      <td>0.445671</td>\n",
       "      <td>0.407648</td>\n",
       "      <td>0.374757</td>\n",
       "      <td>0.302615</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.591638</td>\n",
       "      <td>0.691369</td>\n",
       "      <td>0.551715</td>\n",
       "      <td>0.398224</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.307943</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.944516</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.237570</td>\n",
       "      <td>0.389617</td>\n",
       "      <td>0.391341</td>\n",
       "      <td>0.407266</td>\n",
       "      <td>0.259547</td>\n",
       "      <td>0.531756</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17653</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615563</td>\n",
       "      <td>0.668265</td>\n",
       "      <td>0.610818</td>\n",
       "      <td>0.182036</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.485677</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.490673</td>\n",
       "      <td>0.503279</td>\n",
       "      <td>0.595076</td>\n",
       "      <td>0.438623</td>\n",
       "      <td>0.350809</td>\n",
       "      <td>0.282690</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.591173</td>\n",
       "      <td>0.627071</td>\n",
       "      <td>0.580739</td>\n",
       "      <td>0.303962</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.535807</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.456774</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.689689</td>\n",
       "      <td>0.596175</td>\n",
       "      <td>0.573854</td>\n",
       "      <td>0.452390</td>\n",
       "      <td>0.492557</td>\n",
       "      <td>0.481943</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12161</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659930</td>\n",
       "      <td>0.748256</td>\n",
       "      <td>0.644327</td>\n",
       "      <td>0.177254</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.412903</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.441786</td>\n",
       "      <td>0.427322</td>\n",
       "      <td>0.347199</td>\n",
       "      <td>0.431740</td>\n",
       "      <td>0.339159</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569338</td>\n",
       "      <td>0.707498</td>\n",
       "      <td>0.612401</td>\n",
       "      <td>0.170765</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.645182</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.518710</td>\n",
       "      <td>0.828358</td>\n",
       "      <td>0.479232</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0.478778</td>\n",
       "      <td>0.500574</td>\n",
       "      <td>0.419417</td>\n",
       "      <td>0.514321</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11431</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659466</td>\n",
       "      <td>0.740192</td>\n",
       "      <td>0.614248</td>\n",
       "      <td>0.298156</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>0.696615</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.497419</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>0.626776</td>\n",
       "      <td>0.519525</td>\n",
       "      <td>0.343403</td>\n",
       "      <td>0.273786</td>\n",
       "      <td>0.321295</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.547038</td>\n",
       "      <td>0.658893</td>\n",
       "      <td>0.545646</td>\n",
       "      <td>0.595628</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.4225</td>\n",
       "      <td>0.274740</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.819031</td>\n",
       "      <td>0.213647</td>\n",
       "      <td>0.293443</td>\n",
       "      <td>0.522071</td>\n",
       "      <td>0.513576</td>\n",
       "      <td>0.412298</td>\n",
       "      <td>0.577833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15755</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521252</td>\n",
       "      <td>0.660852</td>\n",
       "      <td>0.579945</td>\n",
       "      <td>0.204850</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.3425</td>\n",
       "      <td>0.655599</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.337419</td>\n",
       "      <td>0.276119</td>\n",
       "      <td>0.793010</td>\n",
       "      <td>0.808743</td>\n",
       "      <td>0.532088</td>\n",
       "      <td>0.560535</td>\n",
       "      <td>0.502913</td>\n",
       "      <td>0.481943</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.577933</td>\n",
       "      <td>0.725370</td>\n",
       "      <td>0.674406</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.662109</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.230323</td>\n",
       "      <td>0.231343</td>\n",
       "      <td>0.813120</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.455857</td>\n",
       "      <td>0.598853</td>\n",
       "      <td>0.523625</td>\n",
       "      <td>0.318804</td>\n",
       "      <td>0.968428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.508246</td>\n",
       "      <td>0.678945</td>\n",
       "      <td>0.587335</td>\n",
       "      <td>0.675546</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.490885</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.245198</td>\n",
       "      <td>0.403279</td>\n",
       "      <td>0.687606</td>\n",
       "      <td>0.518929</td>\n",
       "      <td>0.364401</td>\n",
       "      <td>0.414695</td>\n",
       "      <td>0.968474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-612fa45c-3fa6-4546-8370-00d05cead04f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-612fa45c-3fa6-4546-8370-00d05cead04f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-612fa45c-3fa6-4546-8370-00d05cead04f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       lat       lon   omega_x   omega_y     omega    pr_wtr  rhum_x  rhum_y  \\\n",
       "14064  0.0  0.333333  0.608827  0.732563  0.621372  0.233948  0.0350  0.2375   \n",
       "8981   0.5  0.666667  0.561440  0.625763  0.643536  0.165984  0.1625  0.3450   \n",
       "7703   0.5  0.333333  0.586063  0.734525  0.637731  0.673839  0.1325  0.5625   \n",
       "3731   1.0  0.666667  0.603252  0.688753  0.570449  0.387978  0.1300  0.4025   \n",
       "3370   1.0  0.666667  0.505923  0.491500  0.491293  0.465505  0.1750  0.5400   \n",
       "11919  0.0  0.000000  0.476887  0.644289  0.586016  0.474044  0.1350  0.1050   \n",
       "12309  0.0  0.000000  0.489895  0.680471  0.658575  0.408811  0.0925  0.1950   \n",
       "8047   0.5  0.333333  0.613705  0.728204  0.553298  0.514003  0.0525  0.5050   \n",
       "14446  0.0  0.666667  0.603252  0.676330  0.540106  0.348019  0.0800  0.4375   \n",
       "14983  0.0  0.666667  0.594890  0.657367  0.632718  0.175546  0.1250  0.1075   \n",
       "4113   1.0  0.666667  0.591638  0.691369  0.551715  0.398224  0.0675  0.3325   \n",
       "17653  0.0  1.000000  0.615563  0.668265  0.610818  0.182036  0.0800  0.4950   \n",
       "9998   0.5  0.666667  0.591173  0.627071  0.580739  0.303962  0.3275  0.8400   \n",
       "12161  0.0  0.000000  0.659930  0.748256  0.644327  0.177254  0.1100  0.0500   \n",
       "7105   0.5  0.000000  0.569338  0.707498  0.612401  0.170765  0.0975  0.2400   \n",
       "11431  0.5  1.000000  0.659466  0.740192  0.614248  0.298156  0.2275  0.0800   \n",
       "1652   1.0  0.333333  0.547038  0.658893  0.545646  0.595628  0.1275  0.3175   \n",
       "15755  0.0  1.000000  0.521252  0.660852  0.579945  0.204850  0.1575  0.4900   \n",
       "8994   0.5  0.666667  0.577933  0.725370  0.674406  0.081967  0.0375  0.0800   \n",
       "13092  0.0  0.333333  0.508246  0.678945  0.587335  0.675546  0.2750  0.6750   \n",
       "\n",
       "         rhum       slp     tmp_x     tmp_y       tmp    uwnd_x    uwnd_y  \\\n",
       "14064  0.1900  0.502604  0.687500  0.767097  0.455224  0.234103  0.401093   \n",
       "8981   0.3675  0.710286  0.468750  0.307742  0.268657  0.944525  0.936612   \n",
       "7703   0.5350  0.208984  0.546875  0.872903  0.624999  0.239650  0.347541   \n",
       "3731   0.2725  0.366536  0.687500  0.840645  0.552239  0.297552  0.485792   \n",
       "3370   0.2800  0.239583  0.687500  0.924516  0.529851  0.382844  0.525683   \n",
       "11919  0.5675  0.451172  1.000000  0.776774  0.559701  0.441439  0.492896   \n",
       "12309  0.3725  0.494792  1.000000  0.870968  0.664179  0.295472  0.346995   \n",
       "8047   0.4275  0.330078  0.546875  0.821290  0.552239  0.426531  0.445355   \n",
       "14446  0.2525  0.391927  0.421875  0.828387  0.468284  0.305527  0.403279   \n",
       "14983  0.3425  0.673828  0.421875  0.458065  0.483210  0.486513  0.484153   \n",
       "4113   0.2500  0.307943  0.687500  0.944516  0.597015  0.237570  0.389617   \n",
       "17653  0.1250  0.485677  0.421875  0.667742  0.305970  0.490673  0.503279   \n",
       "9998   0.3250  0.535807  0.468750  0.456774  0.626866  0.689689  0.596175   \n",
       "12161  0.4775  0.740234  1.000000  0.412903  0.738806  0.441786  0.427322   \n",
       "7105   0.2025  0.645182  0.703125  0.518710  0.828358  0.479232  0.486339   \n",
       "11431  0.5325  0.696615  0.562500  0.497419  0.574627  0.600582  0.626776   \n",
       "1652   0.4225  0.274740  0.875000  0.812903  0.819031  0.213647  0.293443   \n",
       "15755  0.3425  0.655599  0.421875  0.337419  0.276119  0.793010  0.808743   \n",
       "8994   0.2050  0.662109  0.468750  0.230323  0.231343  0.813120  0.721311   \n",
       "13092  0.5650  0.490885  0.687500  0.587097  0.731343  0.245198  0.403279   \n",
       "\n",
       "           uwnd    vwnd_x    vwnd_y      vwnd      rain  \n",
       "14064  0.651952  0.326577  0.361812  0.458281  0.968428  \n",
       "8981   0.522071  0.560229  0.506149  0.374844  0.968428  \n",
       "7703   0.513582  0.397706  0.264078  0.724782  0.968428  \n",
       "3731   0.505093  0.404589  0.330744  0.518057  0.968428  \n",
       "3370   0.580645  0.524665  0.464078  0.537983  0.968428  \n",
       "11919  0.668930  0.585851  0.530744  0.582814  0.000000  \n",
       "12309  0.578098  0.583174  0.508091  0.473225  0.000000  \n",
       "8047   0.507640  0.433270  0.363107  0.509340  0.968506  \n",
       "14446  0.679117  0.235564  0.325566  0.377335  0.968428  \n",
       "14983  0.445671  0.407648  0.374757  0.302615  0.968428  \n",
       "4113   0.391341  0.407266  0.259547  0.531756  0.968428  \n",
       "17653  0.595076  0.438623  0.350809  0.282690  0.968428  \n",
       "9998   0.573854  0.452390  0.492557  0.481943  0.968428  \n",
       "12161  0.347199  0.431740  0.339159  0.410959  0.000000  \n",
       "7105   0.478778  0.500574  0.419417  0.514321  0.968428  \n",
       "11431  0.519525  0.343403  0.273786  0.321295  0.968428  \n",
       "1652   0.522071  0.513576  0.412298  0.577833  0.000000  \n",
       "15755  0.532088  0.560535  0.502913  0.481943  0.968428  \n",
       "8994   0.455857  0.598853  0.523625  0.318804  0.968428  \n",
       "13092  0.687606  0.518929  0.364401  0.414695  0.968474  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_Newtrain[num_vars] = scaler.fit_transform(df_Newtrain[num_vars])\n",
    "df_Newtrain.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "id": "0yEQ-zmICctF",
    "outputId": "4773d8f6-9f09-47f1-fc13-3e3870e8c603"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0c89c4e5-b71f-46f3-aed1-8693cda2bc5d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>omega_x</th>\n",
       "      <th>omega_y</th>\n",
       "      <th>omega</th>\n",
       "      <th>pr_wtr</th>\n",
       "      <th>rhum_x</th>\n",
       "      <th>rhum_y</th>\n",
       "      <th>rhum</th>\n",
       "      <th>slp</th>\n",
       "      <th>tmp_x</th>\n",
       "      <th>tmp_y</th>\n",
       "      <th>tmp</th>\n",
       "      <th>uwnd_x</th>\n",
       "      <th>uwnd_y</th>\n",
       "      <th>uwnd</th>\n",
       "      <th>vwnd_x</th>\n",
       "      <th>vwnd_y</th>\n",
       "      <th>vwnd</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584524</td>\n",
       "      <td>0.703558</td>\n",
       "      <td>0.596264</td>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.624041</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.388430</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.812253</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.332652</td>\n",
       "      <td>0.326051</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.506334</td>\n",
       "      <td>0.367294</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.468894</td>\n",
       "      <td>0.622567</td>\n",
       "      <td>0.551485</td>\n",
       "      <td>0.258305</td>\n",
       "      <td>0.366834</td>\n",
       "      <td>0.856777</td>\n",
       "      <td>0.300505</td>\n",
       "      <td>0.617292</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.596837</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0.496568</td>\n",
       "      <td>0.501510</td>\n",
       "      <td>0.566729</td>\n",
       "      <td>0.659117</td>\n",
       "      <td>0.630110</td>\n",
       "      <td>0.581567</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672236</td>\n",
       "      <td>0.766070</td>\n",
       "      <td>0.640565</td>\n",
       "      <td>0.166780</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.107417</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.607756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609354</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.525774</td>\n",
       "      <td>0.421334</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.469482</td>\n",
       "      <td>0.391953</td>\n",
       "      <td>0.564829</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557045</td>\n",
       "      <td>0.719284</td>\n",
       "      <td>0.621648</td>\n",
       "      <td>0.183390</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>0.401515</td>\n",
       "      <td>0.701208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.495838</td>\n",
       "      <td>0.492215</td>\n",
       "      <td>0.570489</td>\n",
       "      <td>0.542802</td>\n",
       "      <td>0.461389</td>\n",
       "      <td>0.548092</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417235</td>\n",
       "      <td>0.474150</td>\n",
       "      <td>0.538554</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>0.801508</td>\n",
       "      <td>0.526854</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.589955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567194</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>0.617041</td>\n",
       "      <td>0.500348</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.668714</td>\n",
       "      <td>0.665152</td>\n",
       "      <td>0.577103</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16313</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513517</td>\n",
       "      <td>0.666797</td>\n",
       "      <td>0.556991</td>\n",
       "      <td>0.711186</td>\n",
       "      <td>0.457286</td>\n",
       "      <td>0.790281</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.389065</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.638472</td>\n",
       "      <td>0.686468</td>\n",
       "      <td>0.125584</td>\n",
       "      <td>0.181966</td>\n",
       "      <td>0.481955</td>\n",
       "      <td>0.493666</td>\n",
       "      <td>0.395198</td>\n",
       "      <td>0.262442</td>\n",
       "      <td>0.975739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6715</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606947</td>\n",
       "      <td>0.760566</td>\n",
       "      <td>0.626437</td>\n",
       "      <td>0.430847</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.465473</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.450731</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.832016</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.299907</td>\n",
       "      <td>0.507519</td>\n",
       "      <td>0.492898</td>\n",
       "      <td>0.406879</td>\n",
       "      <td>0.458826</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9263</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.789624</td>\n",
       "      <td>0.840771</td>\n",
       "      <td>0.655412</td>\n",
       "      <td>0.071525</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.025575</td>\n",
       "      <td>0.133838</td>\n",
       "      <td>0.654800</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.386034</td>\n",
       "      <td>0.558271</td>\n",
       "      <td>0.519568</td>\n",
       "      <td>0.502092</td>\n",
       "      <td>0.667293</td>\n",
       "      <td>0.345873</td>\n",
       "      <td>0.190136</td>\n",
       "      <td>0.279179</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11144</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533963</td>\n",
       "      <td>0.678003</td>\n",
       "      <td>0.678879</td>\n",
       "      <td>0.226441</td>\n",
       "      <td>0.394472</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.682772</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.377470</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.740070</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>0.533835</td>\n",
       "      <td>0.579271</td>\n",
       "      <td>0.399091</td>\n",
       "      <td>0.328275</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.585843</td>\n",
       "      <td>0.716729</td>\n",
       "      <td>0.610393</td>\n",
       "      <td>0.729831</td>\n",
       "      <td>0.419598</td>\n",
       "      <td>0.432225</td>\n",
       "      <td>0.719697</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.822134</td>\n",
       "      <td>0.616541</td>\n",
       "      <td>0.158878</td>\n",
       "      <td>0.201139</td>\n",
       "      <td>0.337406</td>\n",
       "      <td>0.515547</td>\n",
       "      <td>0.425049</td>\n",
       "      <td>0.455479</td>\n",
       "      <td>0.975753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17183</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.456364</td>\n",
       "      <td>0.646747</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>0.142034</td>\n",
       "      <td>0.052764</td>\n",
       "      <td>0.038363</td>\n",
       "      <td>0.376263</td>\n",
       "      <td>0.678957</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.324769</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.555345</td>\n",
       "      <td>0.620613</td>\n",
       "      <td>0.456767</td>\n",
       "      <td>0.675240</td>\n",
       "      <td>0.524984</td>\n",
       "      <td>0.371792</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.694218</td>\n",
       "      <td>0.766464</td>\n",
       "      <td>0.655412</td>\n",
       "      <td>0.324068</td>\n",
       "      <td>0.180905</td>\n",
       "      <td>0.158568</td>\n",
       "      <td>0.330808</td>\n",
       "      <td>0.502861</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.490602</td>\n",
       "      <td>0.283367</td>\n",
       "      <td>0.386474</td>\n",
       "      <td>0.454887</td>\n",
       "      <td>0.278311</td>\n",
       "      <td>0.266061</td>\n",
       "      <td>0.411961</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17353</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596615</td>\n",
       "      <td>0.736387</td>\n",
       "      <td>0.625958</td>\n",
       "      <td>0.530508</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.629156</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.366179</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.820158</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.363318</td>\n",
       "      <td>0.366140</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.422265</td>\n",
       "      <td>0.297859</td>\n",
       "      <td>0.286989</td>\n",
       "      <td>0.975618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.735107</td>\n",
       "      <td>0.781207</td>\n",
       "      <td>0.585010</td>\n",
       "      <td>0.332542</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.493961</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625165</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.412237</td>\n",
       "      <td>0.395770</td>\n",
       "      <td>0.554511</td>\n",
       "      <td>0.366219</td>\n",
       "      <td>0.319922</td>\n",
       "      <td>0.443204</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11722</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579468</td>\n",
       "      <td>0.738156</td>\n",
       "      <td>0.689895</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.066496</td>\n",
       "      <td>0.214646</td>\n",
       "      <td>0.607120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708827</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.288113</td>\n",
       "      <td>0.291773</td>\n",
       "      <td>0.451128</td>\n",
       "      <td>0.469482</td>\n",
       "      <td>0.390007</td>\n",
       "      <td>0.461058</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12068</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588481</td>\n",
       "      <td>0.756831</td>\n",
       "      <td>0.712404</td>\n",
       "      <td>0.493898</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.472346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722661</td>\n",
       "      <td>0.872180</td>\n",
       "      <td>0.243575</td>\n",
       "      <td>0.240065</td>\n",
       "      <td>0.531955</td>\n",
       "      <td>0.473321</td>\n",
       "      <td>0.469825</td>\n",
       "      <td>0.623968</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13433</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.569136</td>\n",
       "      <td>0.746412</td>\n",
       "      <td>0.633860</td>\n",
       "      <td>0.605763</td>\n",
       "      <td>0.075377</td>\n",
       "      <td>0.445013</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.342022</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.783926</td>\n",
       "      <td>0.731203</td>\n",
       "      <td>0.157418</td>\n",
       "      <td>0.313851</td>\n",
       "      <td>0.685150</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.197274</td>\n",
       "      <td>0.526891</td>\n",
       "      <td>0.975484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9188</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.529567</td>\n",
       "      <td>0.667191</td>\n",
       "      <td>0.586446</td>\n",
       "      <td>0.779322</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>0.685422</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.397966</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.614625</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.170196</td>\n",
       "      <td>0.190681</td>\n",
       "      <td>0.343045</td>\n",
       "      <td>0.526679</td>\n",
       "      <td>0.521090</td>\n",
       "      <td>0.552555</td>\n",
       "      <td>0.976145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16350</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507362</td>\n",
       "      <td>0.632198</td>\n",
       "      <td>0.564653</td>\n",
       "      <td>0.733831</td>\n",
       "      <td>0.535176</td>\n",
       "      <td>0.687980</td>\n",
       "      <td>0.954546</td>\n",
       "      <td>0.305658</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.587615</td>\n",
       "      <td>0.621805</td>\n",
       "      <td>0.065713</td>\n",
       "      <td>0.088311</td>\n",
       "      <td>0.240602</td>\n",
       "      <td>0.492438</td>\n",
       "      <td>0.452304</td>\n",
       "      <td>0.490069</td>\n",
       "      <td>0.976695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.475269</td>\n",
       "      <td>0.632003</td>\n",
       "      <td>0.590038</td>\n",
       "      <td>0.801017</td>\n",
       "      <td>0.349246</td>\n",
       "      <td>0.685422</td>\n",
       "      <td>0.815657</td>\n",
       "      <td>0.372537</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.135879</td>\n",
       "      <td>0.181385</td>\n",
       "      <td>0.490601</td>\n",
       "      <td>0.459117</td>\n",
       "      <td>0.266061</td>\n",
       "      <td>0.327159</td>\n",
       "      <td>0.975651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c89c4e5-b71f-46f3-aed1-8693cda2bc5d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0c89c4e5-b71f-46f3-aed1-8693cda2bc5d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0c89c4e5-b71f-46f3-aed1-8693cda2bc5d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       lat       lon   omega_x   omega_y     omega    pr_wtr    rhum_x  \\\n",
       "227    1.0  0.000000  0.584524  0.703558  0.596264  0.455593  0.100503   \n",
       "7583   0.5  0.333333  0.468894  0.622567  0.551485  0.258305  0.366834   \n",
       "12830  0.0  0.000000  0.672236  0.766070  0.640565  0.166780  0.032663   \n",
       "12556  0.0  0.000000  0.557045  0.719284  0.621648  0.183390  0.017588   \n",
       "5461   1.0  1.000000  0.417235  0.474150  0.538554  0.229492  0.801508   \n",
       "16313  0.0  1.000000  0.513517  0.666797  0.556991  0.711186  0.457286   \n",
       "6715   0.5  0.000000  0.606947  0.760566  0.626437  0.430847  0.040201   \n",
       "9263   0.5  0.666667  0.789624  0.840771  0.655412  0.071525  0.040201   \n",
       "11144  0.5  1.000000  0.533963  0.678003  0.678879  0.226441  0.394472   \n",
       "7699   0.5  0.333333  0.585843  0.716729  0.610393  0.729831  0.419598   \n",
       "17183  0.0  1.000000  0.456364  0.646747  0.685345  0.142034  0.052764   \n",
       "2996   1.0  0.666667  0.694218  0.766464  0.655412  0.324068  0.180905   \n",
       "17353  0.0  1.000000  0.596615  0.736387  0.625958  0.530508  0.012563   \n",
       "3867   1.0  0.666667  0.735107  0.781207  0.585010  0.332542  0.027638   \n",
       "11722  0.0  0.000000  0.579468  0.738156  0.689895  0.222034  0.007538   \n",
       "12068  0.0  0.000000  0.588481  0.756831  0.712404  0.493898  0.020101   \n",
       "13433  0.0  0.333333  0.569136  0.746412  0.633860  0.605763  0.075377   \n",
       "9188   0.5  0.666667  0.529567  0.667191  0.586446  0.779322  0.376884   \n",
       "16350  0.0  1.000000  0.507362  0.632198  0.564653  0.733831  0.535176   \n",
       "13464  0.0  0.333333  0.475269  0.632003  0.590038  0.801017  0.349246   \n",
       "\n",
       "         rhum_y      rhum       slp     tmp_x     tmp_y       tmp    uwnd_x  \\\n",
       "227    0.624041  0.371212  0.388430  0.562500  0.812253  0.887218  0.332652   \n",
       "7583   0.856777  0.300505  0.617292  0.546875  0.596837  0.233083  0.496568   \n",
       "12830  0.107417  0.166667  0.607756  1.000000  0.609354  0.932331  0.525774   \n",
       "12556  0.053708  0.401515  0.701208  1.000000  0.393939  0.631579  0.495838   \n",
       "5461   0.526854  0.323232  0.589955  0.000000  0.567194  0.124060  0.617041   \n",
       "16313  0.790281  0.727273  0.389065  0.421875  0.638472  0.686468  0.125584   \n",
       "6715   0.465473  0.454545  0.450731  0.703125  0.832016  0.977444  0.299065   \n",
       "9263   0.025575  0.133838  0.654800  0.468750  0.386034  0.558271  0.519568   \n",
       "11144  0.347826  0.313131  0.682772  0.562500  0.377470  0.315789  0.740070   \n",
       "7699   0.432225  0.719697  0.338843  0.546875  0.822134  0.616541  0.158878   \n",
       "17183  0.038363  0.376263  0.678957  0.421875  0.324769  0.368421  0.555345   \n",
       "2996   0.158568  0.330808  0.502861  0.687500  0.787879  0.490602  0.283367   \n",
       "17353  0.629156  0.522727  0.366179  0.421875  0.820158  0.511278  0.363318   \n",
       "3867   0.143222  0.277778  0.493961  0.687500  0.625165  0.736842  0.412237   \n",
       "11722  0.066496  0.214646  0.607120  1.000000  0.708827  0.887218  0.288113   \n",
       "12068  0.235294  0.500000  0.472346  1.000000  0.722661  0.872180  0.243575   \n",
       "13433  0.445013  0.616162  0.342022  0.687500  0.783926  0.731203  0.157418   \n",
       "9188   0.685422  0.838384  0.397966  0.468750  0.614625  0.699248  0.170196   \n",
       "16350  0.687980  0.954546  0.305658  0.421875  0.587615  0.621805  0.065713   \n",
       "13464  0.685422  0.815657  0.372537  0.687500  0.623188  0.736842  0.135879   \n",
       "\n",
       "         uwnd_y      uwnd    vwnd_x    vwnd_y      vwnd      rain  \n",
       "227    0.326051  0.511278  0.506334  0.367294  0.562598  0.000000  \n",
       "7583   0.501510  0.566729  0.659117  0.630110  0.581567  0.975484  \n",
       "12830  0.421334  0.539474  0.469482  0.391953  0.564829  0.000000  \n",
       "12556  0.492215  0.570489  0.542802  0.461389  0.548092  0.000000  \n",
       "5461   0.500348  0.446429  0.668714  0.665152  0.577103  0.975484  \n",
       "16313  0.181966  0.481955  0.493666  0.395198  0.262442  0.975739  \n",
       "6715   0.299907  0.507519  0.492898  0.406879  0.458826  0.975484  \n",
       "9263   0.502092  0.667293  0.345873  0.190136  0.279179  0.975484  \n",
       "11144  0.729259  0.533835  0.579271  0.399091  0.328275  0.975484  \n",
       "7699   0.201139  0.337406  0.515547  0.425049  0.455479  0.975753  \n",
       "17183  0.620613  0.456767  0.675240  0.524984  0.371792  0.975484  \n",
       "2996   0.386474  0.454887  0.278311  0.266061  0.411961  0.975484  \n",
       "17353  0.366140  0.539474  0.422265  0.297859  0.286989  0.975618  \n",
       "3867   0.395770  0.554511  0.366219  0.319922  0.443204  0.975484  \n",
       "11722  0.291773  0.451128  0.469482  0.390007  0.461058  0.000000  \n",
       "12068  0.240065  0.531955  0.473321  0.469825  0.623968  0.000000  \n",
       "13433  0.313851  0.685150  0.376200  0.197274  0.526891  0.975484  \n",
       "9188   0.190681  0.343045  0.526679  0.521090  0.552555  0.976145  \n",
       "16350  0.088311  0.240602  0.492438  0.452304  0.490069  0.976695  \n",
       "13464  0.181385  0.490601  0.459117  0.266061  0.327159  0.975651  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Newtest[num_vars] = scaler.fit_transform(df_Newtest[num_vars])\n",
    "df_Newtest.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qV9hfoyFCe6X"
   },
   "outputs": [],
   "source": [
    "y_Newtrain = df_Newtrain.pop('rain')\n",
    "X_Newtrain = df_Newtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uyKe_0xECkYL",
    "outputId": "2be6db52-c5b4-4441-88d1-9ff044570fc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7463bfea-aa7e-4471-a4cd-4910d2ebb1f5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>omega_x</th>\n",
       "      <th>omega_y</th>\n",
       "      <th>omega</th>\n",
       "      <th>pr_wtr</th>\n",
       "      <th>rhum_x</th>\n",
       "      <th>rhum_y</th>\n",
       "      <th>rhum</th>\n",
       "      <th>slp</th>\n",
       "      <th>tmp_x</th>\n",
       "      <th>tmp_y</th>\n",
       "      <th>tmp</th>\n",
       "      <th>uwnd_x</th>\n",
       "      <th>uwnd_y</th>\n",
       "      <th>uwnd</th>\n",
       "      <th>vwnd_x</th>\n",
       "      <th>vwnd_y</th>\n",
       "      <th>vwnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14064</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.608827</td>\n",
       "      <td>0.732563</td>\n",
       "      <td>0.621372</td>\n",
       "      <td>0.233948</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.502604</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.767097</td>\n",
       "      <td>0.455224</td>\n",
       "      <td>0.234103</td>\n",
       "      <td>0.401093</td>\n",
       "      <td>0.651952</td>\n",
       "      <td>0.326577</td>\n",
       "      <td>0.361812</td>\n",
       "      <td>0.458281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.561440</td>\n",
       "      <td>0.625763</td>\n",
       "      <td>0.643536</td>\n",
       "      <td>0.165984</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>0.710286</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.307742</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.944525</td>\n",
       "      <td>0.936612</td>\n",
       "      <td>0.522071</td>\n",
       "      <td>0.560229</td>\n",
       "      <td>0.506149</td>\n",
       "      <td>0.374844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.586063</td>\n",
       "      <td>0.734525</td>\n",
       "      <td>0.637731</td>\n",
       "      <td>0.673839</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.208984</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.872903</td>\n",
       "      <td>0.624999</td>\n",
       "      <td>0.239650</td>\n",
       "      <td>0.347541</td>\n",
       "      <td>0.513582</td>\n",
       "      <td>0.397706</td>\n",
       "      <td>0.264078</td>\n",
       "      <td>0.724782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.603252</td>\n",
       "      <td>0.688753</td>\n",
       "      <td>0.570449</td>\n",
       "      <td>0.387978</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.366536</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.840645</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.297552</td>\n",
       "      <td>0.485792</td>\n",
       "      <td>0.505093</td>\n",
       "      <td>0.404589</td>\n",
       "      <td>0.330744</td>\n",
       "      <td>0.518057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.505923</td>\n",
       "      <td>0.491500</td>\n",
       "      <td>0.491293</td>\n",
       "      <td>0.465505</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.924516</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.382844</td>\n",
       "      <td>0.525683</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.524665</td>\n",
       "      <td>0.464078</td>\n",
       "      <td>0.537983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7463bfea-aa7e-4471-a4cd-4910d2ebb1f5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7463bfea-aa7e-4471-a4cd-4910d2ebb1f5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7463bfea-aa7e-4471-a4cd-4910d2ebb1f5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       lat       lon   omega_x   omega_y     omega    pr_wtr  rhum_x  rhum_y  \\\n",
       "14064  0.0  0.333333  0.608827  0.732563  0.621372  0.233948  0.0350  0.2375   \n",
       "8981   0.5  0.666667  0.561440  0.625763  0.643536  0.165984  0.1625  0.3450   \n",
       "7703   0.5  0.333333  0.586063  0.734525  0.637731  0.673839  0.1325  0.5625   \n",
       "3731   1.0  0.666667  0.603252  0.688753  0.570449  0.387978  0.1300  0.4025   \n",
       "3370   1.0  0.666667  0.505923  0.491500  0.491293  0.465505  0.1750  0.5400   \n",
       "\n",
       "         rhum       slp     tmp_x     tmp_y       tmp    uwnd_x    uwnd_y  \\\n",
       "14064  0.1900  0.502604  0.687500  0.767097  0.455224  0.234103  0.401093   \n",
       "8981   0.3675  0.710286  0.468750  0.307742  0.268657  0.944525  0.936612   \n",
       "7703   0.5350  0.208984  0.546875  0.872903  0.624999  0.239650  0.347541   \n",
       "3731   0.2725  0.366536  0.687500  0.840645  0.552239  0.297552  0.485792   \n",
       "3370   0.2800  0.239583  0.687500  0.924516  0.529851  0.382844  0.525683   \n",
       "\n",
       "           uwnd    vwnd_x    vwnd_y      vwnd  \n",
       "14064  0.651952  0.326577  0.361812  0.458281  \n",
       "8981   0.522071  0.560229  0.506149  0.374844  \n",
       "7703   0.513582  0.397706  0.264078  0.724782  \n",
       "3731   0.505093  0.404589  0.330744  0.518057  \n",
       "3370   0.580645  0.524665  0.464078  0.537983  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Newtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QgldVRskCmrF",
    "outputId": "da91866e-1ffb-4c91-a913-dacb0cbf3eea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14064    0.968428\n",
       "8981     0.968428\n",
       "7703     0.968428\n",
       "3731     0.968428\n",
       "3370     0.968428\n",
       "Name: rain, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Newtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BeSM4VwjCpRY",
    "outputId": "bffa66dd-c00b-445c-ae08-482a8e90b5ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y =  [0.96842799 0.96842799 0.96842799 0.96842799 0.96842799]\n"
     ]
    }
   ],
   "source": [
    "y = y_Newtrain.values\n",
    "\n",
    "print('y = ', y[: 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m31LKVbcCric",
    "outputId": "e7d78080-4283-4646-ba22-a6fd92161949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 =  [0.  0.5 0.5 1.  1. ]\n",
      "X2 =  [0.33333333 0.66666667 0.33333333 0.66666667 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "# training set preparation\n",
    "\n",
    "X1 = df_Newtrain.values[:, 0]    \n",
    "X2 = df_Newtrain.values[:, 1]             \n",
    "X3 = df_Newtrain.values[:, 2]               \n",
    "X4 = df_Newtrain.values[:, 3]           \n",
    "X5 = df_Newtrain.values[:, 4]    \n",
    "X6 = df_Newtrain.values[:, 5] \n",
    "X7 = df_Newtrain.values[:, 6] \n",
    "X8 = df_Newtrain.values[:, 7] \n",
    "X9 = df_Newtrain.values[:, 8] \n",
    "X10 = df_Newtrain.values[:, 9] \n",
    "X11 = df_Newtrain.values[:, 10] \n",
    "X12 = df_Newtrain.values[:, 11] \n",
    "X13 = df_Newtrain.values[:, 12] \n",
    "X14 = df_Newtrain.values[:, 13] \n",
    "X15 = df_Newtrain.values[:, 14] \n",
    "X16 = df_Newtrain.values[:, 15] \n",
    "X17 = df_Newtrain.values[:, 16] \n",
    "X18 = df_Newtrain.values[:, 17] \n",
    "X19 = df_Newtrain.values[:, 18] \n",
    "\n",
    "print('X1 = ', X1[: 5]) \n",
    "print('X2 = ', X2[: 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAAsLsaKC7xI",
    "outputId": "88115f89-269f-42d2-e827-e785dab197b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(X_Newtrain)               # size of training set\n",
    "X_0 = np.ones((m, 1))             # Creating a matrix of single column of ones as X0 with the size of training set\n",
    "X_0 [: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ld8SewQdC-hs"
   },
   "outputs": [],
   "source": [
    "# 1D arrays to 2D array conversion\n",
    "X_1 = X1.reshape(m, 1)\n",
    "X_2 = X2.reshape(m, 1)\n",
    "X_3 = X3.reshape(m, 1)\n",
    "X_4 = X4.reshape(m, 1)\n",
    "X_5 = X5.reshape(m, 1)\n",
    "X_6 = X6.reshape(m, 1)\n",
    "X_7 = X7.reshape(m, 1)\n",
    "X_8 = X8.reshape(m, 1)\n",
    "X_9 = X9.reshape(m, 1)\n",
    "X_10 = X10.reshape(m, 1)\n",
    "X_11 = X11.reshape(m, 1)\n",
    "X_12 = X12.reshape(m, 1)\n",
    "X_13 = X13.reshape(m, 1)\n",
    "X_14 = X14.reshape(m, 1)\n",
    "X_15 = X15.reshape(m, 1)\n",
    "X_16 = X16.reshape(m, 1)\n",
    "X_17 = X17.reshape(m, 1)\n",
    "X_18 = X18.reshape(m, 1)\n",
    "X_19 = X19.reshape(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F65zKI5MDF4h"
   },
   "outputs": [],
   "source": [
    "# Final X Matrix for training\n",
    "X = np.hstack((X_0, X_1, X_2, X_3, X_4, X_5, X_6, X_7, X_8, X_9, X_10, X_11, X_12, X_13, X_14, X_15, X_16, X_17, X_18, X_19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UIIciyxDKlI"
   },
   "outputs": [],
   "source": [
    "y_Newtest = df_Newtest.pop('rain')\n",
    "X_Newtest = df_Newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "J9DL9GFwDRNc",
    "outputId": "476fa3a4-96f7-4be0-f0c0-cb75727b97b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f987ed86-4a87-4b1a-aa41-b63b685a3c15\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>omega_x</th>\n",
       "      <th>omega_y</th>\n",
       "      <th>omega</th>\n",
       "      <th>pr_wtr</th>\n",
       "      <th>rhum_x</th>\n",
       "      <th>rhum_y</th>\n",
       "      <th>rhum</th>\n",
       "      <th>slp</th>\n",
       "      <th>tmp_x</th>\n",
       "      <th>tmp_y</th>\n",
       "      <th>tmp</th>\n",
       "      <th>uwnd_x</th>\n",
       "      <th>uwnd_y</th>\n",
       "      <th>uwnd</th>\n",
       "      <th>vwnd_x</th>\n",
       "      <th>vwnd_y</th>\n",
       "      <th>vwnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584524</td>\n",
       "      <td>0.703558</td>\n",
       "      <td>0.596264</td>\n",
       "      <td>0.455593</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.624041</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.388430</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.812253</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.332652</td>\n",
       "      <td>0.326051</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.506334</td>\n",
       "      <td>0.367294</td>\n",
       "      <td>0.562598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.468894</td>\n",
       "      <td>0.622567</td>\n",
       "      <td>0.551485</td>\n",
       "      <td>0.258305</td>\n",
       "      <td>0.366834</td>\n",
       "      <td>0.856777</td>\n",
       "      <td>0.300505</td>\n",
       "      <td>0.617292</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.596837</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0.496568</td>\n",
       "      <td>0.501510</td>\n",
       "      <td>0.566729</td>\n",
       "      <td>0.659117</td>\n",
       "      <td>0.630110</td>\n",
       "      <td>0.581567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672236</td>\n",
       "      <td>0.766070</td>\n",
       "      <td>0.640565</td>\n",
       "      <td>0.166780</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.107417</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.607756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609354</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.525774</td>\n",
       "      <td>0.421334</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.469482</td>\n",
       "      <td>0.391953</td>\n",
       "      <td>0.564829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557045</td>\n",
       "      <td>0.719284</td>\n",
       "      <td>0.621648</td>\n",
       "      <td>0.183390</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>0.401515</td>\n",
       "      <td>0.701208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.495838</td>\n",
       "      <td>0.492215</td>\n",
       "      <td>0.570489</td>\n",
       "      <td>0.542802</td>\n",
       "      <td>0.461389</td>\n",
       "      <td>0.548092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417235</td>\n",
       "      <td>0.474150</td>\n",
       "      <td>0.538554</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>0.801508</td>\n",
       "      <td>0.526854</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.589955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567194</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>0.617041</td>\n",
       "      <td>0.500348</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.668714</td>\n",
       "      <td>0.665152</td>\n",
       "      <td>0.577103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f987ed86-4a87-4b1a-aa41-b63b685a3c15')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f987ed86-4a87-4b1a-aa41-b63b685a3c15 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f987ed86-4a87-4b1a-aa41-b63b685a3c15');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       lat       lon   omega_x   omega_y     omega    pr_wtr    rhum_x  \\\n",
       "227    1.0  0.000000  0.584524  0.703558  0.596264  0.455593  0.100503   \n",
       "7583   0.5  0.333333  0.468894  0.622567  0.551485  0.258305  0.366834   \n",
       "12830  0.0  0.000000  0.672236  0.766070  0.640565  0.166780  0.032663   \n",
       "12556  0.0  0.000000  0.557045  0.719284  0.621648  0.183390  0.017588   \n",
       "5461   1.0  1.000000  0.417235  0.474150  0.538554  0.229492  0.801508   \n",
       "\n",
       "         rhum_y      rhum       slp     tmp_x     tmp_y       tmp    uwnd_x  \\\n",
       "227    0.624041  0.371212  0.388430  0.562500  0.812253  0.887218  0.332652   \n",
       "7583   0.856777  0.300505  0.617292  0.546875  0.596837  0.233083  0.496568   \n",
       "12830  0.107417  0.166667  0.607756  1.000000  0.609354  0.932331  0.525774   \n",
       "12556  0.053708  0.401515  0.701208  1.000000  0.393939  0.631579  0.495838   \n",
       "5461   0.526854  0.323232  0.589955  0.000000  0.567194  0.124060  0.617041   \n",
       "\n",
       "         uwnd_y      uwnd    vwnd_x    vwnd_y      vwnd  \n",
       "227    0.326051  0.511278  0.506334  0.367294  0.562598  \n",
       "7583   0.501510  0.566729  0.659117  0.630110  0.581567  \n",
       "12830  0.421334  0.539474  0.469482  0.391953  0.564829  \n",
       "12556  0.492215  0.570489  0.542802  0.461389  0.548092  \n",
       "5461   0.500348  0.446429  0.668714  0.665152  0.577103  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Newtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJlmmmKMDU19",
    "outputId": "2a0c4112-323d-4c9d-d806-896617af43b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227      0.000000\n",
       "7583     0.975484\n",
       "12830    0.000000\n",
       "12556    0.000000\n",
       "5461     0.975484\n",
       "Name: rain, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Newtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6QkwktSDaaL",
    "outputId": "fd1a6b83-48f8-4feb-9cfd-433adce18716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test =  [0.         0.97548354 0.         0.         0.97548354 0.97573939\n",
      " 0.97548354 0.97548354 0.97548354 0.97575258]\n"
     ]
    }
   ],
   "source": [
    "y_test = y_Newtest.values\n",
    "print('y_test = ', y_test[: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztMkYwnvDkxl",
    "outputId": "2a282943-915a-4fdb-8545-5115646c010e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_test =  [1.  0.5 0.  0.  1.  0.  0.5 0.5 0.5 0.5]\n",
      "X2_test =  [0.         0.33333333 0.         0.         1.         1.\n",
      " 0.         0.66666667 1.         0.33333333]\n",
      "X3_test =  [0.58452406 0.46889424 0.67223564 0.55704549 0.41723455 0.51351704\n",
      " 0.60694651 0.78962409 0.53396349 0.58584303]\n"
     ]
    }
   ],
   "source": [
    "# testing/validarion set preparation\n",
    "X1_test = df_Newtest.values[:, 0]                \n",
    "X2_test = df_Newtest.values[:, 1]                 \n",
    "X3_test = df_Newtest.values[:, 2]               \n",
    "X4_test = df_Newtest.values[:, 3]               \n",
    "X5_test = df_Newtest.values[:, 4]     \n",
    "X6_test = df_Newtest.values[:, 5]\n",
    "X7_test = df_Newtest.values[:, 6]\n",
    "X8_test = df_Newtest.values[:, 7]\n",
    "X9_test = df_Newtest.values[:, 8]\n",
    "X10_test = df_Newtest.values[:, 9]\n",
    "X11_test = df_Newtest.values[:, 10]\n",
    "X12_test = df_Newtest.values[:, 11]\n",
    "X13_test = df_Newtest.values[:, 12]\n",
    "X14_test = df_Newtest.values[:, 13]\n",
    "X15_test = df_Newtest.values[:, 14]\n",
    "X16_test = df_Newtest.values[:, 15]\n",
    "X17_test = df_Newtest.values[:, 16]\n",
    "X18_test = df_Newtest.values[:, 17]\n",
    "X19_test = df_Newtest.values[:, 18]\n",
    "\n",
    "\n",
    "print('X1_test = ', X1_test[: 10]) \n",
    "print('X2_test = ', X2_test[: 10])\n",
    "print('X3_test = ', X3_test[: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_ZgYyr0Dl9R",
    "outputId": "22cf25c4-e60a-411e-b469-28e370765865"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_test = len(X_Newtest)             \n",
    "X_0_test = np.ones((m_test, 1))     # Single column matrix of all ones\n",
    "X_0_test [: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zrsiOyzDshP",
    "outputId": "69a6fcea-9fa3-40b8-b978-b4a8a9996277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1_test =  [[1. ]\n",
      " [0.5]\n",
      " [0. ]\n",
      " [0. ]\n",
      " [1. ]]\n",
      "X_2_test =  [[0.        ]\n",
      " [0.33333333]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 1D arrays of validation X's to 2D array conversion\n",
    "\n",
    "X_1_test = X1_test.reshape(m_test, 1)\n",
    "X_2_test = X2_test.reshape(m_test, 1)\n",
    "X_3_test = X3_test.reshape(m_test, 1)\n",
    "X_4_test = X4_test.reshape(m_test, 1)\n",
    "X_5_test = X5_test.reshape(m_test, 1)\n",
    "X_6_test = X6_test.reshape(m_test, 1)\n",
    "X_7_test = X7_test.reshape(m_test, 1)\n",
    "X_8_test = X8_test.reshape(m_test, 1)\n",
    "X_9_test = X9_test.reshape(m_test, 1)\n",
    "X_10_test = X10_test.reshape(m_test, 1)\n",
    "X_11_test = X11_test.reshape(m_test, 1)\n",
    "X_12_test = X12_test.reshape(m_test, 1)\n",
    "X_13_test = X13_test.reshape(m_test, 1)\n",
    "X_14_test = X14_test.reshape(m_test, 1)\n",
    "X_15_test = X15_test.reshape(m_test, 1)\n",
    "X_16_test = X16_test.reshape(m_test, 1)\n",
    "X_17_test = X17_test.reshape(m_test, 1)\n",
    "X_18_test = X18_test.reshape(m_test, 1)\n",
    "X_19_test = X19_test.reshape(m_test, 1)\n",
    "\n",
    "print('X_1_test = ', X_1_test[: 5])\n",
    "print('X_2_test = ', X_2_test[: 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWfkwhARD0MC"
   },
   "outputs": [],
   "source": [
    "# Final Matrix for validation\n",
    "X_test = np.hstack((X_0_test, X_1_test, X_2_test, X_3_test, X_4_test, X_5_test, X_6_test, X_7_test, X_8_test, X_9_test, X_10_test, X_11_test, X_12_test, X_13_test, X_14_test, X_15_test, X_16_test, X_17_test, X_18_test, X_19_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "P9Oew7RxD1JJ",
    "outputId": "c05794ed-5aac-4e60-d5de-6fbd6723c41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 852)               17892     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 853       \n",
      "=================================================================\n",
      "Total params: 19,165\n",
      "Trainable params: 19,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=20, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(852, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "47SU60OIEF8N",
    "outputId": "5640223c-7266-4536-e624-e04139dd6f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "59/59 [==============================] - 3s 37ms/step - loss: 0.1897 - mse: 0.1897 - mae: 0.3456 - val_loss: 0.0924 - val_mse: 0.0924 - val_mae: 0.2544\n",
      "Epoch 2/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0860 - mse: 0.0860 - mae: 0.2463 - val_loss: 0.0765 - val_mse: 0.0765 - val_mae: 0.2315\n",
      "Epoch 3/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 0.0630 - mse: 0.0630 - mae: 0.1950 - val_loss: 0.0500 - val_mse: 0.0500 - val_mae: 0.1469\n",
      "Epoch 4/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.1240 - val_loss: 0.0348 - val_mse: 0.0348 - val_mae: 0.1090\n",
      "Epoch 5/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0308 - mse: 0.0308 - mae: 0.1004 - val_loss: 0.0309 - val_mse: 0.0309 - val_mae: 0.0952\n",
      "Epoch 6/250\n",
      "59/59 [==============================] - 1s 19ms/step - loss: 0.0241 - mse: 0.0241 - mae: 0.0880 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0798\n",
      "Epoch 7/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0774 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0646\n",
      "Epoch 8/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0583 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0574\n",
      "Epoch 9/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0430 - val_loss: 0.0025 - val_mse: 0.0025 - val_mae: 0.0334\n",
      "Epoch 10/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0301 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0251\n",
      "Epoch 11/250\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0248 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0206\n",
      "Epoch 12/250\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 0.0010 - mse: 0.0010 - mae: 0.0197 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0186\n",
      "Epoch 13/250\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 8.6446e-04 - mse: 8.6446e-04 - mae: 0.0184 - val_loss: 9.0569e-04 - val_mse: 9.0569e-04 - val_mae: 0.0194\n",
      "Epoch 14/250\n",
      "59/59 [==============================] - 1s 24ms/step - loss: 6.8172e-04 - mse: 6.8172e-04 - mae: 0.0161 - val_loss: 5.7373e-04 - val_mse: 5.7373e-04 - val_mae: 0.0151\n",
      "Epoch 15/250\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 5.6308e-04 - mse: 5.6308e-04 - mae: 0.0152 - val_loss: 4.8631e-04 - val_mse: 4.8631e-04 - val_mae: 0.0132\n",
      "Epoch 16/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 4.8332e-04 - mse: 4.8332e-04 - mae: 0.0139 - val_loss: 3.8401e-04 - val_mse: 3.8401e-04 - val_mae: 0.0112\n",
      "Epoch 17/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 4.0210e-04 - mse: 4.0210e-04 - mae: 0.0126 - val_loss: 2.9034e-04 - val_mse: 2.9034e-04 - val_mae: 0.0099\n",
      "Epoch 18/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 3.4220e-04 - mse: 3.4220e-04 - mae: 0.0119 - val_loss: 2.5905e-04 - val_mse: 2.5905e-04 - val_mae: 0.0097\n",
      "Epoch 19/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 2.2725e-04 - mse: 2.2725e-04 - mae: 0.0091 - val_loss: 2.0706e-04 - val_mse: 2.0706e-04 - val_mae: 0.0087\n",
      "Epoch 20/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 2.1178e-04 - mse: 2.1178e-04 - mae: 0.0093 - val_loss: 1.6733e-04 - val_mse: 1.6733e-04 - val_mae: 0.0075\n",
      "Epoch 21/250\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 1.9481e-04 - mse: 1.9481e-04 - mae: 0.0093 - val_loss: 1.5507e-04 - val_mse: 1.5507e-04 - val_mae: 0.0072\n",
      "Epoch 22/250\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 1.7482e-04 - mse: 1.7482e-04 - mae: 0.0086 - val_loss: 1.1985e-04 - val_mse: 1.1985e-04 - val_mae: 0.0064\n",
      "Epoch 23/250\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 1.2160e-04 - mse: 1.2160e-04 - mae: 0.0070 - val_loss: 1.1244e-04 - val_mse: 1.1244e-04 - val_mae: 0.0064\n",
      "Epoch 24/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.0794e-04 - mse: 1.0794e-04 - mae: 0.0069 - val_loss: 1.1772e-04 - val_mse: 1.1772e-04 - val_mae: 0.0066\n",
      "Epoch 25/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 8.5377e-05 - mse: 8.5377e-05 - mae: 0.0059 - val_loss: 8.1230e-05 - val_mse: 8.1230e-05 - val_mae: 0.0058\n",
      "Epoch 26/250\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 9.1539e-05 - mse: 9.1539e-05 - mae: 0.0065 - val_loss: 6.6279e-05 - val_mse: 6.6279e-05 - val_mae: 0.0050\n",
      "Epoch 27/250\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 8.9267e-05 - mse: 8.9267e-05 - mae: 0.0065 - val_loss: 6.7280e-05 - val_mse: 6.7280e-05 - val_mae: 0.0053\n",
      "Epoch 28/250\n",
      "59/59 [==============================] - 1s 19ms/step - loss: 5.8055e-05 - mse: 5.8055e-05 - mae: 0.0050 - val_loss: 6.0842e-05 - val_mse: 6.0842e-05 - val_mae: 0.0049\n",
      "Epoch 29/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 7.0847e-05 - mse: 7.0847e-05 - mae: 0.0059 - val_loss: 6.2496e-05 - val_mse: 6.2496e-05 - val_mae: 0.0052\n",
      "Epoch 30/250\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 4.5342e-05 - mse: 4.5342e-05 - mae: 0.0045 - val_loss: 5.4317e-05 - val_mse: 5.4317e-05 - val_mae: 0.0048\n",
      "Epoch 31/250\n",
      "59/59 [==============================] - 2s 26ms/step - loss: 4.6758e-05 - mse: 4.6758e-05 - mae: 0.0045 - val_loss: 5.0836e-05 - val_mse: 5.0836e-05 - val_mae: 0.0047\n",
      "Epoch 32/250\n",
      "59/59 [==============================] - 1s 21ms/step - loss: 4.3127e-05 - mse: 4.3127e-05 - mae: 0.0045 - val_loss: 3.1588e-05 - val_mse: 3.1588e-05 - val_mae: 0.0036\n",
      "Epoch 33/250\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 3.0681e-05 - mse: 3.0681e-05 - mae: 0.0038 - val_loss: 3.1992e-05 - val_mse: 3.1992e-05 - val_mae: 0.0037\n",
      "Epoch 34/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 3.0357e-05 - mse: 3.0357e-05 - mae: 0.0038 - val_loss: 4.0032e-05 - val_mse: 4.0032e-05 - val_mae: 0.0040\n",
      "Epoch 35/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 5.7214e-05 - mse: 5.7214e-05 - mae: 0.0055 - val_loss: 3.5303e-05 - val_mse: 3.5303e-05 - val_mae: 0.0040\n",
      "Epoch 36/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 4.2444e-05 - mse: 4.2444e-05 - mae: 0.0045 - val_loss: 4.7066e-05 - val_mse: 4.7066e-05 - val_mae: 0.0048\n",
      "Epoch 37/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 7.6165e-05 - mse: 7.6165e-05 - mae: 0.0063 - val_loss: 5.4682e-05 - val_mse: 5.4682e-05 - val_mae: 0.0053\n",
      "Epoch 38/250\n",
      "59/59 [==============================] - 1s 19ms/step - loss: 2.9393e-05 - mse: 2.9393e-05 - mae: 0.0037 - val_loss: 2.0469e-05 - val_mse: 2.0469e-05 - val_mae: 0.0029\n",
      "Epoch 39/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 2.0321e-05 - mse: 2.0321e-05 - mae: 0.0031 - val_loss: 1.8011e-05 - val_mse: 1.8011e-05 - val_mae: 0.0027\n",
      "Epoch 40/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 3.8534e-05 - mse: 3.8534e-05 - mae: 0.0044 - val_loss: 1.8654e-05 - val_mse: 1.8654e-05 - val_mae: 0.0027\n",
      "Epoch 41/250\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 2.5487e-05 - mse: 2.5487e-05 - mae: 0.0035 - val_loss: 1.7067e-05 - val_mse: 1.7067e-05 - val_mae: 0.0027\n",
      "Epoch 42/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 2.0492e-05 - mse: 2.0492e-05 - mae: 0.0032 - val_loss: 1.3852e-05 - val_mse: 1.3852e-05 - val_mae: 0.0023\n",
      "Epoch 43/250\n",
      "59/59 [==============================] - 1s 19ms/step - loss: 1.8120e-05 - mse: 1.8120e-05 - mae: 0.0030 - val_loss: 1.4377e-05 - val_mse: 1.4377e-05 - val_mae: 0.0024\n",
      "Epoch 44/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.6614e-05 - mse: 1.6614e-05 - mae: 0.0028 - val_loss: 1.4627e-05 - val_mse: 1.4627e-05 - val_mae: 0.0024\n",
      "Epoch 45/250\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 2.7581e-05 - mse: 2.7581e-05 - mae: 0.0037 - val_loss: 1.7318e-05 - val_mse: 1.7318e-05 - val_mae: 0.0027\n",
      "Epoch 46/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.1564e-05 - mse: 1.1564e-05 - mae: 0.0024 - val_loss: 1.2536e-05 - val_mse: 1.2536e-05 - val_mae: 0.0023\n",
      "Epoch 47/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 1.5081e-05 - mse: 1.5081e-05 - mae: 0.0028 - val_loss: 1.2728e-05 - val_mse: 1.2728e-05 - val_mae: 0.0023\n",
      "Epoch 48/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.9051e-05 - mse: 1.9051e-05 - mae: 0.0030 - val_loss: 9.9590e-06 - val_mse: 9.9590e-06 - val_mae: 0.0020\n",
      "Epoch 49/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 2.0341e-05 - mse: 2.0341e-05 - mae: 0.0033 - val_loss: 6.6091e-05 - val_mse: 6.6091e-05 - val_mae: 0.0071\n",
      "Epoch 50/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 3.8676e-05 - mse: 3.8676e-05 - mae: 0.0045 - val_loss: 3.4148e-05 - val_mse: 3.4148e-05 - val_mae: 0.0047\n",
      "Epoch 51/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.8829e-04 - mse: 1.8829e-04 - mae: 0.0095 - val_loss: 0.0011 - val_mse: 0.0011 - val_mae: 0.0294\n",
      "Epoch 52/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.5829e-04 - mse: 1.5829e-04 - mae: 0.0068 - val_loss: 1.7197e-05 - val_mse: 1.7197e-05 - val_mae: 0.0029\n",
      "Epoch 53/250\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 2.5138e-05 - mse: 2.5138e-05 - mae: 0.0035 - val_loss: 1.4335e-05 - val_mse: 1.4335e-05 - val_mae: 0.0026\n",
      "Epoch 54/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 4.2802e-05 - mse: 4.2802e-05 - mae: 0.0048 - val_loss: 9.5740e-05 - val_mse: 9.5740e-05 - val_mae: 0.0065\n",
      "Epoch 55/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 3.2818e-04 - mse: 3.2818e-04 - mae: 0.0123 - val_loss: 8.2330e-04 - val_mse: 8.2330e-04 - val_mae: 0.0214\n",
      "Epoch 56/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 1.4228e-04 - mse: 1.4228e-04 - mae: 0.0084 - val_loss: 6.4901e-05 - val_mse: 6.4901e-05 - val_mae: 0.0072\n",
      "Epoch 57/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 7.3359e-05 - mse: 7.3359e-05 - mae: 0.0060 - val_loss: 3.6082e-05 - val_mse: 3.6082e-05 - val_mae: 0.0051\n",
      "Epoch 58/250\n",
      "59/59 [==============================] - 1s 23ms/step - loss: 2.8429e-05 - mse: 2.8429e-05 - mae: 0.0037 - val_loss: 1.6886e-05 - val_mse: 1.6886e-05 - val_mae: 0.0029\n",
      "Epoch 59/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.2631e-05 - mse: 1.2631e-05 - mae: 0.0026 - val_loss: 3.7011e-05 - val_mse: 3.7011e-05 - val_mae: 0.0042\n",
      "Epoch 60/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.0677e-05 - mse: 1.0677e-05 - mae: 0.0023 - val_loss: 1.5135e-05 - val_mse: 1.5135e-05 - val_mae: 0.0027\n",
      "Epoch 61/250\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 4.6323e-05 - mse: 4.6323e-05 - mae: 0.0043 - val_loss: 2.1811e-04 - val_mse: 2.1811e-04 - val_mae: 0.0122\n",
      "Epoch 62/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 3.3578e-05 - mse: 3.3578e-05 - mae: 0.0036 - val_loss: 7.1560e-06 - val_mse: 7.1560e-06 - val_mae: 0.0016\n",
      "Epoch 63/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 1.4813e-05 - mse: 1.4813e-05 - mae: 0.0027 - val_loss: 2.6899e-05 - val_mse: 2.6899e-05 - val_mae: 0.0046\n",
      "Epoch 64/250\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 2.1537e-05 - mse: 2.1537e-05 - mae: 0.0033 - val_loss: 1.1305e-05 - val_mse: 1.1305e-05 - val_mae: 0.0023\n",
      "Epoch 65/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 6.6322e-05 - mse: 6.6322e-05 - mae: 0.0050 - val_loss: 8.6772e-05 - val_mse: 8.6772e-05 - val_mae: 0.0064\n",
      "Epoch 66/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.2861e-04 - mse: 1.2861e-04 - mae: 0.0079 - val_loss: 3.8968e-05 - val_mse: 3.8968e-05 - val_mae: 0.0055\n",
      "Epoch 67/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 4.3376e-05 - mse: 4.3376e-05 - mae: 0.0044 - val_loss: 1.0470e-05 - val_mse: 1.0470e-05 - val_mae: 0.0021\n",
      "Epoch 68/250\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 2.2960e-04 - mse: 2.2960e-04 - mae: 0.0098 - val_loss: 5.6080e-04 - val_mse: 5.6080e-04 - val_mae: 0.0150\n",
      "Epoch 69/250\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 2.1461e-04 - mse: 2.1461e-04 - mae: 0.0099 - val_loss: 4.6766e-05 - val_mse: 4.6766e-05 - val_mae: 0.0042\n",
      "Epoch 70/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 2.6588e-05 - mse: 2.6588e-05 - mae: 0.0035 - val_loss: 2.9574e-05 - val_mse: 2.9574e-05 - val_mae: 0.0041\n",
      "Epoch 71/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 6.0241e-05 - mse: 6.0241e-05 - mae: 0.0056 - val_loss: 4.1925e-05 - val_mse: 4.1925e-05 - val_mae: 0.0038\n",
      "Epoch 72/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 7.9618e-05 - mse: 7.9618e-05 - mae: 0.0065 - val_loss: 8.1833e-05 - val_mse: 8.1833e-05 - val_mae: 0.0053\n",
      "Epoch 73/250\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 3.9644e-05 - mse: 3.9644e-05 - mae: 0.0039 - val_loss: 9.9809e-06 - val_mse: 9.9809e-06 - val_mae: 0.0023\n",
      "Epoch 74/250\n",
      "59/59 [==============================] - 1s 22ms/step - loss: 1.7601e-05 - mse: 1.7601e-05 - mae: 0.0031 - val_loss: 1.2055e-05 - val_mse: 1.2055e-05 - val_mae: 0.0023\n",
      "Epoch 75/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 7.3710e-06 - mse: 7.3710e-06 - mae: 0.0020 - val_loss: 5.7526e-06 - val_mse: 5.7526e-06 - val_mae: 0.0015\n",
      "Epoch 76/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 1.5946e-05 - mse: 1.5946e-05 - mae: 0.0027 - val_loss: 1.8124e-05 - val_mse: 1.8124e-05 - val_mae: 0.0030\n",
      "Epoch 77/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 1.3068e-05 - mse: 1.3068e-05 - mae: 0.0025 - val_loss: 9.3604e-06 - val_mse: 9.3604e-06 - val_mae: 0.0020\n",
      "Epoch 78/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 3.3979e-05 - mse: 3.3979e-05 - mae: 0.0043 - val_loss: 5.5256e-05 - val_mse: 5.5256e-05 - val_mae: 0.0043\n",
      "Epoch 79/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 9.6515e-05 - mse: 9.6515e-05 - mae: 0.0069 - val_loss: 6.6370e-04 - val_mse: 6.6370e-04 - val_mae: 0.0184\n",
      "Epoch 80/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 1.8576e-04 - mse: 1.8576e-04 - mae: 0.0095 - val_loss: 5.1660e-05 - val_mse: 5.1660e-05 - val_mae: 0.0049\n",
      "Epoch 81/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.6177e-04 - mse: 1.6177e-04 - mae: 0.0081 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0298\n",
      "Epoch 82/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 3.1386e-04 - mse: 3.1386e-04 - mae: 0.0124 - val_loss: 3.2860e-05 - val_mse: 3.2860e-05 - val_mae: 0.0045\n",
      "Epoch 83/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 2.9536e-05 - mse: 2.9536e-05 - mae: 0.0035 - val_loss: 8.4158e-06 - val_mse: 8.4158e-06 - val_mae: 0.0019\n",
      "Epoch 84/250\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 8.0133e-06 - mse: 8.0133e-06 - mae: 0.0019 - val_loss: 2.9717e-05 - val_mse: 2.9717e-05 - val_mae: 0.0039\n",
      "Epoch 85/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.7097e-05 - mse: 1.7097e-05 - mae: 0.0030 - val_loss: 1.4675e-05 - val_mse: 1.4675e-05 - val_mae: 0.0023\n",
      "Epoch 86/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 7.1868e-06 - mse: 7.1868e-06 - mae: 0.0019 - val_loss: 1.1015e-05 - val_mse: 1.1015e-05 - val_mae: 0.0021\n",
      "Epoch 87/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 5.8609e-06 - mse: 5.8609e-06 - mae: 0.0017 - val_loss: 6.9361e-06 - val_mse: 6.9361e-06 - val_mae: 0.0018\n",
      "Epoch 88/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.2657e-05 - mse: 1.2657e-05 - mae: 0.0026 - val_loss: 1.6374e-05 - val_mse: 1.6374e-05 - val_mae: 0.0032\n",
      "Epoch 89/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 2.9422e-05 - mse: 2.9422e-05 - mae: 0.0039 - val_loss: 1.3639e-05 - val_mse: 1.3639e-05 - val_mae: 0.0023\n",
      "Epoch 90/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.9556e-05 - mse: 3.9556e-05 - mae: 0.0040 - val_loss: 1.7918e-04 - val_mse: 1.7918e-04 - val_mae: 0.0091\n",
      "Epoch 91/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.3271e-04 - mse: 2.3271e-04 - mae: 0.0103 - val_loss: 5.8119e-05 - val_mse: 5.8119e-05 - val_mae: 0.0056\n",
      "Epoch 92/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 6.1758e-05 - mse: 6.1758e-05 - mae: 0.0056 - val_loss: 1.7465e-05 - val_mse: 1.7465e-05 - val_mae: 0.0026\n",
      "Epoch 93/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.4662e-04 - mse: 2.4662e-04 - mae: 0.0108 - val_loss: 3.6128e-05 - val_mse: 3.6128e-05 - val_mae: 0.0045\n",
      "Epoch 94/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 3.7803e-05 - mse: 3.7803e-05 - mae: 0.0040 - val_loss: 1.3516e-05 - val_mse: 1.3516e-05 - val_mae: 0.0022\n",
      "Epoch 95/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 6.6196e-06 - mse: 6.6196e-06 - mae: 0.0018 - val_loss: 8.4199e-06 - val_mse: 8.4199e-06 - val_mae: 0.0019\n",
      "Epoch 96/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0080e-05 - mse: 1.0080e-05 - mae: 0.0022 - val_loss: 1.1607e-05 - val_mse: 1.1607e-05 - val_mae: 0.0021\n",
      "Epoch 97/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.3072e-05 - mse: 2.3072e-05 - mae: 0.0033 - val_loss: 7.0952e-06 - val_mse: 7.0952e-06 - val_mae: 0.0017\n",
      "Epoch 98/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 8.7850e-06 - mse: 8.7850e-06 - mae: 0.0020 - val_loss: 6.4409e-05 - val_mse: 6.4409e-05 - val_mae: 0.0059\n",
      "Epoch 99/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.3860e-05 - mse: 3.3860e-05 - mae: 0.0041 - val_loss: 1.3707e-05 - val_mse: 1.3707e-05 - val_mae: 0.0032\n",
      "Epoch 100/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.6058e-05 - mse: 2.6058e-05 - mae: 0.0037 - val_loss: 5.1567e-04 - val_mse: 5.1567e-04 - val_mae: 0.0167\n",
      "Epoch 101/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.6748e-04 - mse: 2.6748e-04 - mae: 0.0116 - val_loss: 9.2625e-05 - val_mse: 9.2625e-05 - val_mae: 0.0086\n",
      "Epoch 102/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.4163e-04 - mse: 1.4163e-04 - mae: 0.0078 - val_loss: 9.5757e-06 - val_mse: 9.5757e-06 - val_mae: 0.0018\n",
      "Epoch 103/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 9.4439e-06 - mse: 9.4439e-06 - mae: 0.0022 - val_loss: 1.5807e-05 - val_mse: 1.5807e-05 - val_mae: 0.0029\n",
      "Epoch 104/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 8.3344e-06 - mse: 8.3344e-06 - mae: 0.0020 - val_loss: 6.0023e-05 - val_mse: 6.0023e-05 - val_mae: 0.0056\n",
      "Epoch 105/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.7892e-05 - mse: 4.7892e-05 - mae: 0.0050 - val_loss: 2.6522e-05 - val_mse: 2.6522e-05 - val_mae: 0.0031\n",
      "Epoch 106/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.2657e-05 - mse: 1.2657e-05 - mae: 0.0025 - val_loss: 8.8939e-06 - val_mse: 8.8939e-06 - val_mae: 0.0023\n",
      "Epoch 107/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.6907e-05 - mse: 1.6907e-05 - mae: 0.0028 - val_loss: 9.7997e-06 - val_mse: 9.7997e-06 - val_mae: 0.0019\n",
      "Epoch 108/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3944e-05 - mse: 1.3944e-05 - mae: 0.0026 - val_loss: 8.8520e-06 - val_mse: 8.8520e-06 - val_mae: 0.0025\n",
      "Epoch 109/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 8.3057e-06 - mse: 8.3057e-06 - mae: 0.0021 - val_loss: 1.8351e-05 - val_mse: 1.8351e-05 - val_mae: 0.0037\n",
      "Epoch 110/250\n",
      "59/59 [==============================] - 1s 8ms/step - loss: 3.5415e-05 - mse: 3.5415e-05 - mae: 0.0042 - val_loss: 4.4366e-05 - val_mse: 4.4366e-05 - val_mae: 0.0043\n",
      "Epoch 111/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.7647e-05 - mse: 1.7647e-05 - mae: 0.0030 - val_loss: 6.6815e-05 - val_mse: 6.6815e-05 - val_mae: 0.0049\n",
      "Epoch 112/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 7.5670e-04 - mse: 7.5670e-04 - mae: 0.0180 - val_loss: 6.1912e-05 - val_mse: 6.1912e-05 - val_mae: 0.0052\n",
      "Epoch 113/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.8142e-04 - mse: 2.8142e-04 - mae: 0.0107 - val_loss: 3.8725e-05 - val_mse: 3.8725e-05 - val_mae: 0.0038\n",
      "Epoch 114/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.2243e-05 - mse: 3.2243e-05 - mae: 0.0036 - val_loss: 2.8426e-05 - val_mse: 2.8426e-05 - val_mae: 0.0032\n",
      "Epoch 115/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.8547e-05 - mse: 1.8547e-05 - mae: 0.0030 - val_loss: 3.2888e-05 - val_mse: 3.2888e-05 - val_mae: 0.0042\n",
      "Epoch 116/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 7.2694e-06 - mse: 7.2694e-06 - mae: 0.0018 - val_loss: 8.5776e-06 - val_mse: 8.5776e-06 - val_mae: 0.0018\n",
      "Epoch 117/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.3623e-05 - mse: 3.3623e-05 - mae: 0.0041 - val_loss: 2.1467e-05 - val_mse: 2.1467e-05 - val_mae: 0.0038\n",
      "Epoch 118/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0080e-05 - mse: 1.0080e-05 - mae: 0.0023 - val_loss: 5.6573e-06 - val_mse: 5.6573e-06 - val_mae: 0.0014\n",
      "Epoch 119/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1378e-05 - mse: 1.1378e-05 - mae: 0.0023 - val_loss: 4.0756e-06 - val_mse: 4.0756e-06 - val_mae: 0.0011\n",
      "Epoch 120/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 3.5587e-06 - mse: 3.5587e-06 - mae: 0.0013 - val_loss: 5.7884e-06 - val_mse: 5.7884e-06 - val_mae: 0.0015\n",
      "Epoch 121/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 6.4112e-06 - mse: 6.4112e-06 - mae: 0.0018 - val_loss: 8.3040e-06 - val_mse: 8.3040e-06 - val_mae: 0.0022\n",
      "Epoch 122/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.5561e-06 - mse: 5.5561e-06 - mae: 0.0016 - val_loss: 1.3329e-05 - val_mse: 1.3329e-05 - val_mae: 0.0029\n",
      "Epoch 123/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.6356e-06 - mse: 5.6356e-06 - mae: 0.0016 - val_loss: 2.4477e-05 - val_mse: 2.4477e-05 - val_mae: 0.0040\n",
      "Epoch 124/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 8.6866e-06 - mse: 8.6866e-06 - mae: 0.0019 - val_loss: 4.9128e-06 - val_mse: 4.9128e-06 - val_mae: 0.0017\n",
      "Epoch 125/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0815e-05 - mse: 1.0815e-05 - mae: 0.0023 - val_loss: 7.1113e-06 - val_mse: 7.1113e-06 - val_mae: 0.0020\n",
      "Epoch 126/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1818e-05 - mse: 1.1818e-05 - mae: 0.0025 - val_loss: 4.7681e-06 - val_mse: 4.7681e-06 - val_mae: 0.0013\n",
      "Epoch 127/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 9.0163e-05 - mse: 9.0163e-05 - mae: 0.0053 - val_loss: 2.2077e-04 - val_mse: 2.2077e-04 - val_mae: 0.0126\n",
      "Epoch 128/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.6302e-05 - mse: 2.6302e-05 - mae: 0.0033 - val_loss: 4.0952e-05 - val_mse: 4.0952e-05 - val_mae: 0.0047\n",
      "Epoch 129/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.7551e-05 - mse: 3.7551e-05 - mae: 0.0045 - val_loss: 1.7638e-05 - val_mse: 1.7638e-05 - val_mae: 0.0034\n",
      "Epoch 130/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.6031e-05 - mse: 4.6031e-05 - mae: 0.0048 - val_loss: 3.9495e-05 - val_mse: 3.9495e-05 - val_mae: 0.0056\n",
      "Epoch 131/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.3462e-05 - mse: 4.3462e-05 - mae: 0.0047 - val_loss: 9.3803e-06 - val_mse: 9.3803e-06 - val_mae: 0.0024\n",
      "Epoch 132/250\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 3.1546e-05 - mse: 3.1546e-05 - mae: 0.0039 - val_loss: 1.7423e-05 - val_mse: 1.7423e-05 - val_mae: 0.0028\n",
      "Epoch 133/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.0185e-04 - mse: 2.0185e-04 - mae: 0.0092 - val_loss: 1.2551e-04 - val_mse: 1.2551e-04 - val_mae: 0.0106\n",
      "Epoch 134/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 7.2261e-05 - mse: 7.2261e-05 - mae: 0.0058 - val_loss: 2.8627e-05 - val_mse: 2.8627e-05 - val_mae: 0.0042\n",
      "Epoch 135/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.1182e-05 - mse: 2.1182e-05 - mae: 0.0033 - val_loss: 6.5281e-06 - val_mse: 6.5281e-06 - val_mae: 0.0020\n",
      "Epoch 136/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 7.0439e-06 - mse: 7.0439e-06 - mae: 0.0019 - val_loss: 5.4171e-06 - val_mse: 5.4171e-06 - val_mae: 0.0015\n",
      "Epoch 137/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.4800e-05 - mse: 1.4800e-05 - mae: 0.0028 - val_loss: 1.4797e-05 - val_mse: 1.4797e-05 - val_mae: 0.0027\n",
      "Epoch 138/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.5000e-05 - mse: 1.5000e-05 - mae: 0.0026 - val_loss: 4.8528e-06 - val_mse: 4.8528e-06 - val_mae: 0.0016\n",
      "Epoch 139/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.8675e-05 - mse: 5.8675e-05 - mae: 0.0054 - val_loss: 7.7203e-05 - val_mse: 7.7203e-05 - val_mae: 0.0044\n",
      "Epoch 140/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1757e-04 - mse: 1.1757e-04 - mae: 0.0073 - val_loss: 1.6264e-04 - val_mse: 1.6264e-04 - val_mae: 0.0078\n",
      "Epoch 141/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.0183e-04 - mse: 5.0183e-04 - mae: 0.0157 - val_loss: 1.7601e-04 - val_mse: 1.7601e-04 - val_mae: 0.0090\n",
      "Epoch 142/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.7352e-04 - mse: 4.7352e-04 - mae: 0.0139 - val_loss: 5.1644e-05 - val_mse: 5.1644e-05 - val_mae: 0.0053\n",
      "Epoch 143/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.0602e-05 - mse: 2.0602e-05 - mae: 0.0030 - val_loss: 7.9959e-06 - val_mse: 7.9959e-06 - val_mae: 0.0016\n",
      "Epoch 144/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 6.9256e-06 - mse: 6.9256e-06 - mae: 0.0018 - val_loss: 9.2398e-06 - val_mse: 9.2398e-06 - val_mae: 0.0018\n",
      "Epoch 145/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 5.7029e-06 - mse: 5.7029e-06 - mae: 0.0016 - val_loss: 1.4743e-05 - val_mse: 1.4743e-05 - val_mae: 0.0029\n",
      "Epoch 146/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 6.7303e-06 - mse: 6.7303e-06 - mae: 0.0018 - val_loss: 9.4763e-06 - val_mse: 9.4763e-06 - val_mae: 0.0019\n",
      "Epoch 147/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 5.1730e-06 - mse: 5.1730e-06 - mae: 0.0015 - val_loss: 4.8308e-06 - val_mse: 4.8308e-06 - val_mae: 0.0013\n",
      "Epoch 148/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 3.6492e-06 - mse: 3.6492e-06 - mae: 0.0013 - val_loss: 3.3999e-06 - val_mse: 3.3999e-06 - val_mae: 9.7115e-04\n",
      "Epoch 149/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 4.6486e-06 - mse: 4.6486e-06 - mae: 0.0015 - val_loss: 1.2109e-05 - val_mse: 1.2109e-05 - val_mae: 0.0024\n",
      "Epoch 150/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.3860e-05 - mse: 1.3860e-05 - mae: 0.0027 - val_loss: 8.5180e-06 - val_mse: 8.5180e-06 - val_mae: 0.0019\n",
      "Epoch 151/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.0233e-06 - mse: 4.0233e-06 - mae: 0.0014 - val_loss: 6.4884e-06 - val_mse: 6.4884e-06 - val_mae: 0.0019\n",
      "Epoch 152/250\n",
      "59/59 [==============================] - 1s 10ms/step - loss: 4.7786e-06 - mse: 4.7786e-06 - mae: 0.0015 - val_loss: 2.5600e-06 - val_mse: 2.5600e-06 - val_mae: 8.2489e-04\n",
      "Epoch 153/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 6.8946e-06 - mse: 6.8946e-06 - mae: 0.0017 - val_loss: 1.5336e-05 - val_mse: 1.5336e-05 - val_mae: 0.0027\n",
      "Epoch 154/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.2568e-05 - mse: 1.2568e-05 - mae: 0.0026 - val_loss: 9.9729e-06 - val_mse: 9.9729e-06 - val_mae: 0.0023\n",
      "Epoch 155/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 2.8511e-05 - mse: 2.8511e-05 - mae: 0.0036 - val_loss: 1.2072e-05 - val_mse: 1.2072e-05 - val_mae: 0.0025\n",
      "Epoch 156/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 3.2121e-05 - mse: 3.2121e-05 - mae: 0.0037 - val_loss: 7.9894e-06 - val_mse: 7.9894e-06 - val_mae: 0.0017\n",
      "Epoch 157/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.1919e-05 - mse: 1.1919e-05 - mae: 0.0021 - val_loss: 2.4855e-05 - val_mse: 2.4855e-05 - val_mae: 0.0039\n",
      "Epoch 158/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 9.8727e-05 - mse: 9.8727e-05 - mae: 0.0067 - val_loss: 1.8082e-05 - val_mse: 1.8082e-05 - val_mae: 0.0027\n",
      "Epoch 159/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 8.8282e-05 - mse: 8.8282e-05 - mae: 0.0066 - val_loss: 3.6841e-05 - val_mse: 3.6841e-05 - val_mae: 0.0051\n",
      "Epoch 160/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 9.9592e-06 - mse: 9.9592e-06 - mae: 0.0020 - val_loss: 7.3986e-06 - val_mse: 7.3986e-06 - val_mae: 0.0022\n",
      "Epoch 161/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 5.8503e-06 - mse: 5.8503e-06 - mae: 0.0017 - val_loss: 9.2581e-06 - val_mse: 9.2581e-06 - val_mae: 0.0022\n",
      "Epoch 162/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 9.1631e-06 - mse: 9.1631e-06 - mae: 0.0021 - val_loss: 3.3696e-05 - val_mse: 3.3696e-05 - val_mae: 0.0045\n",
      "Epoch 163/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.5839e-05 - mse: 1.5839e-05 - mae: 0.0028 - val_loss: 8.2095e-06 - val_mse: 8.2095e-06 - val_mae: 0.0021\n",
      "Epoch 164/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.3011e-04 - mse: 1.3011e-04 - mae: 0.0074 - val_loss: 1.0289e-05 - val_mse: 1.0289e-05 - val_mae: 0.0021\n",
      "Epoch 165/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 3.2801e-05 - mse: 3.2801e-05 - mae: 0.0039 - val_loss: 3.0719e-05 - val_mse: 3.0719e-05 - val_mae: 0.0041\n",
      "Epoch 166/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.1801e-05 - mse: 5.1801e-05 - mae: 0.0050 - val_loss: 1.3631e-05 - val_mse: 1.3631e-05 - val_mae: 0.0024\n",
      "Epoch 167/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.0902e-05 - mse: 3.0902e-05 - mae: 0.0035 - val_loss: 3.8886e-06 - val_mse: 3.8886e-06 - val_mae: 0.0010\n",
      "Epoch 168/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.6476e-05 - mse: 4.6476e-05 - mae: 0.0042 - val_loss: 1.1546e-05 - val_mse: 1.1546e-05 - val_mae: 0.0022\n",
      "Epoch 169/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0265e-05 - mse: 1.0265e-05 - mae: 0.0022 - val_loss: 4.9603e-06 - val_mse: 4.9603e-06 - val_mae: 0.0016\n",
      "Epoch 170/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.9104e-05 - mse: 2.9104e-05 - mae: 0.0035 - val_loss: 1.9852e-05 - val_mse: 1.9852e-05 - val_mae: 0.0024\n",
      "Epoch 171/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.6914e-05 - mse: 4.6914e-05 - mae: 0.0048 - val_loss: 4.1906e-06 - val_mse: 4.1906e-06 - val_mae: 0.0013\n",
      "Epoch 172/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0441e-05 - mse: 1.0441e-05 - mae: 0.0023 - val_loss: 5.8724e-06 - val_mse: 5.8724e-06 - val_mae: 0.0013\n",
      "Epoch 173/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.5958e-05 - mse: 2.5958e-05 - mae: 0.0035 - val_loss: 5.9274e-05 - val_mse: 5.9274e-05 - val_mae: 0.0049\n",
      "Epoch 174/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.5203e-05 - mse: 1.5203e-05 - mae: 0.0027 - val_loss: 1.3277e-04 - val_mse: 1.3277e-04 - val_mae: 0.0071\n",
      "Epoch 175/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0288 - val_loss: 3.6584e-04 - val_mse: 3.6584e-04 - val_mae: 0.0120\n",
      "Epoch 176/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0940e-04 - mse: 1.0940e-04 - mae: 0.0061 - val_loss: 4.8686e-05 - val_mse: 4.8686e-05 - val_mae: 0.0040\n",
      "Epoch 177/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.9376e-05 - mse: 2.9376e-05 - mae: 0.0034 - val_loss: 2.2712e-05 - val_mse: 2.2712e-05 - val_mae: 0.0029\n",
      "Epoch 178/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.1589e-05 - mse: 2.1589e-05 - mae: 0.0030 - val_loss: 1.3703e-05 - val_mse: 1.3703e-05 - val_mae: 0.0020\n",
      "Epoch 179/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 1.0631e-05 - mse: 1.0631e-05 - mae: 0.0021 - val_loss: 9.9753e-06 - val_mse: 9.9753e-06 - val_mae: 0.0019\n",
      "Epoch 180/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 7.9947e-06 - mse: 7.9947e-06 - mae: 0.0018 - val_loss: 1.5030e-05 - val_mse: 1.5030e-05 - val_mae: 0.0028\n",
      "Epoch 181/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 7.4990e-06 - mse: 7.4990e-06 - mae: 0.0019 - val_loss: 7.1855e-06 - val_mse: 7.1855e-06 - val_mae: 0.0016\n",
      "Epoch 182/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.1022e-06 - mse: 5.1022e-06 - mae: 0.0015 - val_loss: 7.0982e-06 - val_mse: 7.0982e-06 - val_mae: 0.0015\n",
      "Epoch 183/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.8471e-06 - mse: 5.8471e-06 - mae: 0.0016 - val_loss: 4.9675e-06 - val_mse: 4.9675e-06 - val_mae: 0.0012\n",
      "Epoch 184/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 4.4013e-06 - mse: 4.4013e-06 - mae: 0.0014 - val_loss: 5.3991e-06 - val_mse: 5.3991e-06 - val_mae: 0.0014\n",
      "Epoch 185/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.7888e-06 - mse: 3.7888e-06 - mae: 0.0013 - val_loss: 5.2136e-06 - val_mse: 5.2136e-06 - val_mae: 0.0013\n",
      "Epoch 186/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.4103e-06 - mse: 3.4103e-06 - mae: 0.0013 - val_loss: 3.7506e-06 - val_mse: 3.7506e-06 - val_mae: 0.0012\n",
      "Epoch 187/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.8539e-06 - mse: 4.8539e-06 - mae: 0.0015 - val_loss: 4.2778e-06 - val_mse: 4.2778e-06 - val_mae: 0.0013\n",
      "Epoch 188/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.0867e-06 - mse: 5.0867e-06 - mae: 0.0016 - val_loss: 2.2627e-05 - val_mse: 2.2627e-05 - val_mae: 0.0035\n",
      "Epoch 189/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.7944e-06 - mse: 3.7944e-06 - mae: 0.0014 - val_loss: 3.6653e-06 - val_mse: 3.6653e-06 - val_mae: 0.0013\n",
      "Epoch 190/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 3.7962e-06 - mse: 3.7962e-06 - mae: 0.0014 - val_loss: 2.8379e-06 - val_mse: 2.8379e-06 - val_mae: 0.0010\n",
      "Epoch 191/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.8192e-06 - mse: 2.8192e-06 - mae: 0.0012 - val_loss: 2.9585e-06 - val_mse: 2.9585e-06 - val_mae: 0.0010\n",
      "Epoch 192/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 5.0234e-06 - mse: 5.0234e-06 - mae: 0.0016 - val_loss: 3.5556e-06 - val_mse: 3.5556e-06 - val_mae: 0.0013\n",
      "Epoch 193/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.5695e-06 - mse: 2.5695e-06 - mae: 0.0011 - val_loss: 4.0607e-06 - val_mse: 4.0607e-06 - val_mae: 0.0014\n",
      "Epoch 194/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.3224e-06 - mse: 3.3224e-06 - mae: 0.0013 - val_loss: 4.8817e-06 - val_mse: 4.8817e-06 - val_mae: 0.0014\n",
      "Epoch 195/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 6.7288e-06 - mse: 6.7288e-06 - mae: 0.0019 - val_loss: 4.3143e-06 - val_mse: 4.3143e-06 - val_mae: 0.0015\n",
      "Epoch 196/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 6.3827e-06 - mse: 6.3827e-06 - mae: 0.0018 - val_loss: 1.1859e-05 - val_mse: 1.1859e-05 - val_mae: 0.0023\n",
      "Epoch 197/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 9.3043e-05 - mse: 9.3043e-05 - mae: 0.0062 - val_loss: 2.0796e-05 - val_mse: 2.0796e-05 - val_mae: 0.0031\n",
      "Epoch 198/250\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 8.6370e-06 - mse: 8.6370e-06 - mae: 0.0020 - val_loss: 3.6201e-06 - val_mse: 3.6201e-06 - val_mae: 0.0012\n",
      "Epoch 199/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 4.3734e-06 - mse: 4.3734e-06 - mae: 0.0015 - val_loss: 1.1407e-05 - val_mse: 1.1407e-05 - val_mae: 0.0027\n",
      "Epoch 200/250\n",
      "59/59 [==============================] - 1s 8ms/step - loss: 1.2605e-05 - mse: 1.2605e-05 - mae: 0.0024 - val_loss: 4.8513e-06 - val_mse: 4.8513e-06 - val_mae: 0.0016\n",
      "Epoch 201/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1079e-05 - mse: 1.1079e-05 - mae: 0.0023 - val_loss: 1.4815e-05 - val_mse: 1.4815e-05 - val_mae: 0.0029\n",
      "Epoch 202/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.9665e-06 - mse: 3.9665e-06 - mae: 0.0014 - val_loss: 7.5959e-06 - val_mse: 7.5959e-06 - val_mae: 0.0019\n",
      "Epoch 203/250\n",
      "59/59 [==============================] - 1s 9ms/step - loss: 5.7665e-06 - mse: 5.7665e-06 - mae: 0.0017 - val_loss: 2.1669e-05 - val_mse: 2.1669e-05 - val_mae: 0.0034\n",
      "Epoch 204/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.1969e-05 - mse: 1.1969e-05 - mae: 0.0026 - val_loss: 1.6078e-05 - val_mse: 1.6078e-05 - val_mae: 0.0036\n",
      "Epoch 205/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 6.6415e-06 - mse: 6.6415e-06 - mae: 0.0019 - val_loss: 2.7440e-06 - val_mse: 2.7440e-06 - val_mae: 0.0012\n",
      "Epoch 206/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.8308e-04 - mse: 1.8308e-04 - mae: 0.0077 - val_loss: 3.8523e-05 - val_mse: 3.8523e-05 - val_mae: 0.0037\n",
      "Epoch 207/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0209e-04 - mse: 1.0209e-04 - mae: 0.0073 - val_loss: 5.6708e-05 - val_mse: 5.6708e-05 - val_mae: 0.0043\n",
      "Epoch 208/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0488e-04 - mse: 1.0488e-04 - mae: 0.0072 - val_loss: 5.1388e-05 - val_mse: 5.1388e-05 - val_mae: 0.0058\n",
      "Epoch 209/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.6075e-05 - mse: 1.6075e-05 - mae: 0.0029 - val_loss: 6.3546e-06 - val_mse: 6.3546e-06 - val_mae: 0.0016\n",
      "Epoch 210/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 7.9773e-06 - mse: 7.9773e-06 - mae: 0.0019 - val_loss: 9.1054e-06 - val_mse: 9.1054e-06 - val_mae: 0.0023\n",
      "Epoch 211/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.9165e-05 - mse: 3.9165e-05 - mae: 0.0044 - val_loss: 1.0537e-04 - val_mse: 1.0537e-04 - val_mae: 0.0085\n",
      "Epoch 212/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 6.0379e-05 - mse: 6.0379e-05 - mae: 0.0052 - val_loss: 6.2060e-04 - val_mse: 6.2060e-04 - val_mae: 0.0211\n",
      "Epoch 213/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.6762e-04 - mse: 2.6762e-04 - mae: 0.0109 - val_loss: 3.8537e-05 - val_mse: 3.8537e-05 - val_mae: 0.0041\n",
      "Epoch 214/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.1851e-05 - mse: 2.1851e-05 - mae: 0.0031 - val_loss: 1.4748e-05 - val_mse: 1.4748e-05 - val_mae: 0.0026\n",
      "Epoch 215/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 5.3629e-06 - mse: 5.3629e-06 - mae: 0.0015 - val_loss: 7.7912e-06 - val_mse: 7.7912e-06 - val_mae: 0.0016\n",
      "Epoch 216/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 7.8236e-06 - mse: 7.8236e-06 - mae: 0.0019 - val_loss: 4.3123e-05 - val_mse: 4.3123e-05 - val_mae: 0.0053\n",
      "Epoch 217/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 1.2842e-05 - mse: 1.2842e-05 - mae: 0.0026 - val_loss: 4.5118e-06 - val_mse: 4.5118e-06 - val_mae: 0.0013\n",
      "Epoch 218/250\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 3.7817e-06 - mse: 3.7817e-06 - mae: 0.0013 - val_loss: 5.2198e-06 - val_mse: 5.2198e-06 - val_mae: 0.0016\n",
      "Epoch 219/250\n",
      "59/59 [==============================] - 1s 25ms/step - loss: 3.6724e-06 - mse: 3.6724e-06 - mae: 0.0013 - val_loss: 9.0722e-06 - val_mse: 9.0722e-06 - val_mae: 0.0020\n",
      "Epoch 220/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 7.8658e-06 - mse: 7.8658e-06 - mae: 0.0019 - val_loss: 4.1593e-06 - val_mse: 4.1593e-06 - val_mae: 0.0012\n",
      "Epoch 221/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 5.1874e-06 - mse: 5.1874e-06 - mae: 0.0016 - val_loss: 5.3703e-06 - val_mse: 5.3703e-06 - val_mae: 0.0014\n",
      "Epoch 222/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 4.4574e-06 - mse: 4.4574e-06 - mae: 0.0015 - val_loss: 3.3112e-06 - val_mse: 3.3112e-06 - val_mae: 0.0012\n",
      "Epoch 223/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 7.2986e-06 - mse: 7.2986e-06 - mae: 0.0018 - val_loss: 8.8073e-06 - val_mse: 8.8073e-06 - val_mae: 0.0021\n",
      "Epoch 224/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 6.2655e-05 - mse: 6.2655e-05 - mae: 0.0052 - val_loss: 1.9614e-04 - val_mse: 1.9614e-04 - val_mae: 0.0094\n",
      "Epoch 225/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 3.5281e-04 - mse: 3.5281e-04 - mae: 0.0133 - val_loss: 1.0445e-04 - val_mse: 1.0445e-04 - val_mae: 0.0096\n",
      "Epoch 226/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 4.1967e-05 - mse: 4.1967e-05 - mae: 0.0043 - val_loss: 7.1931e-06 - val_mse: 7.1931e-06 - val_mae: 0.0017\n",
      "Epoch 227/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 6.7295e-06 - mse: 6.7295e-06 - mae: 0.0018 - val_loss: 6.6141e-06 - val_mse: 6.6141e-06 - val_mae: 0.0016\n",
      "Epoch 228/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 5.0487e-06 - mse: 5.0487e-06 - mae: 0.0016 - val_loss: 1.7706e-05 - val_mse: 1.7706e-05 - val_mae: 0.0028\n",
      "Epoch 229/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 4.0898e-06 - mse: 4.0898e-06 - mae: 0.0013 - val_loss: 3.8847e-06 - val_mse: 3.8847e-06 - val_mae: 0.0013\n",
      "Epoch 230/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.5155e-05 - mse: 1.5155e-05 - mae: 0.0027 - val_loss: 5.5276e-06 - val_mse: 5.5276e-06 - val_mae: 0.0016\n",
      "Epoch 231/250\n",
      "59/59 [==============================] - 1s 12ms/step - loss: 4.9902e-06 - mse: 4.9902e-06 - mae: 0.0015 - val_loss: 5.4811e-06 - val_mse: 5.4811e-06 - val_mae: 0.0019\n",
      "Epoch 232/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 5.0249e-06 - mse: 5.0249e-06 - mae: 0.0016 - val_loss: 7.1594e-06 - val_mse: 7.1594e-06 - val_mae: 0.0017\n",
      "Epoch 233/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 1.0278e-05 - mse: 1.0278e-05 - mae: 0.0022 - val_loss: 2.8351e-06 - val_mse: 2.8351e-06 - val_mae: 0.0010\n",
      "Epoch 234/250\n",
      "59/59 [==============================] - 1s 20ms/step - loss: 6.3588e-05 - mse: 6.3588e-05 - mae: 0.0052 - val_loss: 2.4494e-04 - val_mse: 2.4494e-04 - val_mae: 0.0093\n",
      "Epoch 235/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.1160e-04 - mse: 1.1160e-04 - mae: 0.0079 - val_loss: 9.9649e-05 - val_mse: 9.9649e-05 - val_mae: 0.0054\n",
      "Epoch 236/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 6.5945e-05 - mse: 6.5945e-05 - mae: 0.0056 - val_loss: 2.2778e-05 - val_mse: 2.2778e-05 - val_mae: 0.0030\n",
      "Epoch 237/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 9.1559e-06 - mse: 9.1559e-06 - mae: 0.0021 - val_loss: 5.0754e-06 - val_mse: 5.0754e-06 - val_mae: 0.0017\n",
      "Epoch 238/250\n",
      "59/59 [==============================] - 1s 14ms/step - loss: 9.7463e-06 - mse: 9.7463e-06 - mae: 0.0022 - val_loss: 5.4192e-06 - val_mse: 5.4192e-06 - val_mae: 0.0019\n",
      "Epoch 239/250\n",
      "59/59 [==============================] - 1s 11ms/step - loss: 1.1185e-05 - mse: 1.1185e-05 - mae: 0.0021 - val_loss: 2.2470e-06 - val_mse: 2.2470e-06 - val_mae: 9.3933e-04\n",
      "Epoch 240/250\n",
      "59/59 [==============================] - 1s 13ms/step - loss: 6.8352e-06 - mse: 6.8352e-06 - mae: 0.0018 - val_loss: 2.9078e-05 - val_mse: 2.9078e-05 - val_mae: 0.0042\n",
      "Epoch 241/250\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 2.2946e-05 - mse: 2.2946e-05 - mae: 0.0033 - val_loss: 4.9150e-05 - val_mse: 4.9150e-05 - val_mae: 0.0046\n",
      "Epoch 242/250\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 1.7520e-05 - mse: 1.7520e-05 - mae: 0.0029 - val_loss: 1.5861e-05 - val_mse: 1.5861e-05 - val_mae: 0.0034\n",
      "Epoch 243/250\n",
      "59/59 [==============================] - 1s 15ms/step - loss: 5.4796e-06 - mse: 5.4796e-06 - mae: 0.0016 - val_loss: 1.4138e-05 - val_mse: 1.4138e-05 - val_mae: 0.0027\n",
      "Epoch 244/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 2.4761e-04 - mse: 2.4761e-04 - mae: 0.0102 - val_loss: 8.3162e-05 - val_mse: 8.3162e-05 - val_mae: 0.0060\n",
      "Epoch 245/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.5665e-04 - mse: 1.5665e-04 - mae: 0.0085 - val_loss: 2.1030e-05 - val_mse: 2.1030e-05 - val_mae: 0.0038\n",
      "Epoch 246/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 2.6387e-05 - mse: 2.6387e-05 - mae: 0.0035 - val_loss: 4.3269e-05 - val_mse: 4.3269e-05 - val_mae: 0.0041\n",
      "Epoch 247/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.7371e-05 - mse: 1.7371e-05 - mae: 0.0028 - val_loss: 1.6628e-05 - val_mse: 1.6628e-05 - val_mae: 0.0025\n",
      "Epoch 248/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.1725e-05 - mse: 3.1725e-05 - mae: 0.0037 - val_loss: 5.5801e-06 - val_mse: 5.5801e-06 - val_mae: 0.0016\n",
      "Epoch 249/250\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 3.1143e-06 - mse: 3.1143e-06 - mae: 0.0012 - val_loss: 2.5527e-06 - val_mse: 2.5527e-06 - val_mae: 9.3428e-04\n",
      "Epoch 250/250\n",
      "59/59 [==============================] - 0s 8ms/step - loss: 2.7746e-06 - mse: 2.7746e-06 - mae: 0.0011 - val_loss: 2.9033e-06 - val_mse: 2.9033e-06 - val_mae: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "history=model.fit(X, y, epochs=250, batch_size=150, verbose=1, validation_split=0.3)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "Zz69UyY-D9Wx",
    "outputId": "c9fdc86e-f642-45ea-8db7-1024ecae33ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hcVZ3v//enujt9y62TNJCrCYIQApiEEBi5COIl4AioIHFQgccho0d+6JkzHoNzRIejc3R+/tTHGQbFA96GiwyK5Izhx8gAXkbABAwhCQQCJOQC5Ebu6Wt9zx97d6f6XtXp6mrSn9fz1NO71l5713d1Vde391p7r62IwMzMLF+ZUgdgZmZvLk4cZmZWECcOMzMriBOHmZkVxInDzMwK4sRhZmYFceIwKyJJP5L01Tzrrpf07sPdj1mxOXGYmVlBnDjMzKwgThw27KVdRJ+XtFLSfkm3STpa0gOS9kp6SFJdTv2LJa2WtEvSo5Jm5qybI+mpdLufAVWdXuvPJa1It/2DpFP7GfO1ktZJ2ilpiaRJabkkfVvSVkl7JD0j6eR03UWS1qSxbZb0N/36hdmw58Rhlvgw8B7gbcAHgAeALwL1JH8n1wNIehtwF/C5dN1S4P9IGiFpBPBL4KfAOOBf0/2SbjsHuB34K2A88H1giaTKQgKV9C7gfwEfASYCG4C709XvBc5N2zEmrbMjXXcb8FcRMQo4GXi4kNc1a+PEYZb4x4h4PSI2A78DnoiIP0VEA3AfMCetdwXwq4j4dUQ0A98EqoF3AGcCFcB3IqI5Iu4FluW8xiLg+xHxRES0RsSPgcZ0u0JcCdweEU9FRCNwA/BnkqYDzcAo4ERAEfFsRLyabtcMnCRpdES8ERFPFfi6ZoATh1mb13OWD3bzfGS6PInkP3wAIiILbAQmp+s2R8eZQzfkLL8F+G9pN9UuSbuAqel2hegcwz6So4rJEfEw8E/AzcBWSbdKGp1W/TBwEbBB0m8k/VmBr2sGOHGYFWoLSQIAkjEFki//zcCrwOS0rM20nOWNwNciYmzOoyYi7jrMGGpJur42A0TEdyPiNOAkki6rz6flyyLiEuAoki61ewp8XTPAicOsUPcA75d0gaQK4L+RdDf9AXgMaAGul1Qh6UPA/JxtfwB8StIZ6SB2raT3SxpVYAx3AddImp2Oj/w9Sdfaekmnp/uvAPYDDUA2HYO5UtKYtIttD5A9jN+DDWNOHGYFiIi1wMeAfwS2kwykfyAimiKiCfgQcDWwk2Q85Bc52y4HriXpSnoDWJfWLTSGh4AvAT8nOcp5K7AwXT2aJEG9QdKdtQP4f9N1HwfWS9oDfIpkrMSsYPKNnMzMrBA+4jAzs4I4cZiZWUGcOMzMrCBOHGZmVpDyUgcwGCZMmBDTp08vdRhmZm8qTz755PaIqO9cPiwSx/Tp01m+fHmpwzAze1ORtKG7cndVmZlZQZw4zMysIE4cZmZWkGExxtGd5uZmNm3aRENDQ6lDOSJUVVUxZcoUKioqSh2KmRXZsE0cmzZtYtSoUUyfPp2Ok5laoSKCHTt2sGnTJmbMmFHqcMysyIZtV1VDQwPjx4930hgAkhg/fryP3syGiWGbOAAnjQHk36XZ8DGsE0df3jjQxI59jaUOw8xsSHHi6MWuA83s3N9UnH3v2sU///M/F7zdRRddxK5du4oQkZlZfpw4elHMzpeeEkdLS0uv2y1dupSxY8cWKywzsz4N27Oq8lWs21wtXryYF198kdmzZ1NRUUFVVRV1dXU899xzPP/881x66aVs3LiRhoYGPvvZz7Jo0SLg0PQp+/bt48ILL+Tss8/mD3/4A5MnT+b++++nurq6SBGbmSWcOIC/+z+rWbNlT5fyxpZWslmoHlFW8D5PmjSaL39gVo/rv/71r7Nq1SpWrFjBo48+yvvf/35WrVrVfjrr7bffzrhx4zh48CCnn346H/7whxk/fnyHfbzwwgvcdddd/OAHP+AjH/kIP//5z/nYxz5WcKxmZoVw4hgi5s+f3+EaiO9+97vcd999AGzcuJEXXnihS+KYMWMGs2fPBuC0005j/fr1gxavmQ1fThzQ45HBKzsOcLC5lROOGVX0GGpra9uXH330UR566CEee+wxampqOO+887q9RqKysrJ9uaysjIMHDxY9TjMzD473RhBFGuUYNWoUe/fu7Xbd7t27qauro6amhueee47HH3+8KDGYmfWHjzh6ISja6Pj48eM566yzOPnkk6muruboo49uX7dgwQK+973vMXPmTE444QTOPPPM4gRhZtYPiijWeUNDx7x586LzjZyeffZZZs6c2et2G3ceYF9jCzMnji5meEeMfH6nZvbmIenJiJjXudxdVb3wLBpmZl05cfRhGByQmZkVxImjF0IU7xJAM7M3p6ImDkkLJK2VtE7S4m7WnyvpKUktki7LKT9f0oqcR4OkS9N1P5L0cs662cWL32nDzKyzop1VJakMuBl4D7AJWCZpSUSsyan2CnA18De520bEI8DsdD/jgHXAv+dU+XxE3Fus2Dtw5jAz66CYp+POB9ZFxEsAku4GLgHaE0dErE/XZXvZz2XAAxFxoHih9sx5w8yso2J2VU0GNuY835SWFWohcFensq9JWinp25Iqu9toIAyls6pGjhwJwJYtW7jsssu6rXPeeefR+bTjzr7zne9w4MChHOxp2s2sUEN6cFzSROAU4MGc4huAE4HTgXHAF3rYdpGk5ZKWb9u2rd8xDLUjjkmTJnHvvf3vpeucODxNu5kVqpiJYzMwNef5lLSsEB8B7ouI5raCiHg1Eo3AD0m6xLqIiFsjYl5EzKuvry/wZRNCRTsfd/Hixdx8883tz7/yla/w1a9+lQsuuIC5c+dyyimncP/993fZbv369Zx88skAHDx4kIULFzJz5kw++MEPdpir6tOf/jTz5s1j1qxZfPnLXwaSiRO3bNnC+eefz/nnnw8k07Rv374dgG9961ucfPLJnHzyyXznO99pf72ZM2dy7bXXMmvWLN773vd6TiyzYa6YYxzLgOMlzSBJGAuBvyhwHx8lOcJoJ2liRLyq5CbXlwKrDjvSBxbDa890KR7XmmVkS5aoLEtPzS3AMafAhV/vcfUVV1zB5z73OT7zmc8AcM899/Dggw9y/fXXM3r0aLZv386ZZ57JxRdf3OP9vG+55RZqamp49tlnWblyJXPnzm1f97WvfY1x48bR2trKBRdcwMqVK7n++uv51re+xSOPPMKECRM67OvJJ5/khz/8IU888QQRwRlnnME73/lO6urqPH27mXVQtCOOiGgBriPpZnoWuCciVku6SdLFAJJOl7QJuBz4vqTVbdtLmk5yxPKbTru+Q9IzwDPABOCrxWpDMc2ZM4etW7eyZcsWnn76aerq6jjmmGP44he/yKmnnsq73/1uNm/ezOuvv97jPn7729+2f4GfeuqpnHrqqe3r7rnnHubOncucOXNYvXo1a9as6Wk3APz+97/ngx/8ILW1tYwcOZIPfehD/O53vwM8fbuZdVTUSQ4jYimwtFPZjTnLy0i6sLrbdj3dDKZHxLsGNkp6PDLYtaeB1/Y0cPLkMT3+1384Lr/8cu69915ee+01rrjiCu644w62bdvGk08+SUVFBdOnT+92OvW+vPzyy3zzm99k2bJl1NXVcfXVV/drP208fbuZ5RrSg+Ml15YrijRCfsUVV3D33Xdz7733cvnll7N7926OOuooKioqeOSRR9iwYUOv25977rnceeedAKxatYqVK1cCsGfPHmpraxkzZgyvv/46DzzwQPs2PU3nfs455/DLX/6SAwcOsH//fu677z7OOeecAWytmR0pPK16L4qcN5g1axZ79+5l8uTJTJw4kSuvvJIPfOADnHLKKcybN48TTzyx1+0//elPc8011zBz5kxmzpzJaaedBsDb3/525syZw4knnsjUqVM566yz2rdZtGgRCxYsYNKkSTzyyCPt5XPnzuXqq69m/vzkXIO//Mu/ZM6cOe6WMrMuPK16L7btbeTV3QeZNWk0ZRkfnPXF06qbHVk8rfphGAa51cwsb04cvRhKV46bmQ0Vwzpx9NVNV+wxjiPJcOjyNLPEsE0cVVVV7Nixw194AyAi2LFjB1VVVaUOxcwGwbA9q2rKlCls2rSJ3uax2t/YwhsHmsnsrqIs436r3lRVVTFlSreX5JjZEWbYJo6KigpmzJjRa517lm/kvy9Zye/++/lMHVczSJGZmQ1tw7arKh9l6eh41t1ZZmbtnDh60dY91Zp14jAza+PE0YtMxkccZmadOXH0om083AccZmaHOHH0om2Mw11VZmaHOHH0IuMxDjOzLpw4euGzqszMunLi6IXPqjIz66qoiUPSAklrJa2TtLib9edKekpSi6TLOq1rlbQifSzJKZ8h6Yl0nz+TNKJY8fusKjOzroqWOCSVATcDFwInAR+VdFKnaq8AVwN3drOLgxExO31cnFP+DeDbEXEc8AbwyQEPPnVocLxYr2Bm9uZTzCOO+cC6iHgpIpqAu4FLcitExPqIWAnk9dWs5Mbf7wLuTYt+DFw6cCF31HbvJndVmZkdUszEMRnYmPN8U1qWrypJyyU9LqktOYwHdkVESz/3WRAPjpuZdTWUJzl8S0RslnQs8LCkZ4Dd+W4saRGwCGDatGn9CsCD42ZmXRXziGMzMDXn+ZS0LC8RsTn9+RLwKDAH2AGMldSW8HrcZ0TcGhHzImJefX194dED8hGHmVkXxUwcy4Dj07OgRgALgSV9bAOApDpJlenyBOAsYE0kd116BGg7A+sq4P4BjzxV5rOqzMy6KFriSMchrgMeBJ4F7omI1ZJuknQxgKTTJW0CLge+L2l1uvlMYLmkp0kSxdcjYk267gvAX0taRzLmcVux2uCzqszMuirqGEdELAWWdiq7MWd5GUl3U+ft/gCc0sM+XyI5Y6vofFaVmVlXvnK8F+6qMjPryomjF54d18ysKyeOXnjKETOzrpw4euEjDjOzrpw4euELAM3MunLi6EVbV5V7qszMDnHi6EXbPcdbnTnMzNo5cfTCYxxmZl05cfTCZ1WZmXXlxNELH3GYmXXlxNGLjM+qMjPrwomjF55yxMysKyeOXnh2XDOzrpw4etE2O66POMzMDnHi6IUHx83MunLi6EXGt441M+vCiaMX7ddx+IjDzKydE0cfyjLylCNmZjmKmjgkLZC0VtI6SYu7WX+upKcktUi6LKd8tqTHJK2WtFLSFTnrfiTpZUkr0sfsYrahTPJZVWZmOYp2z3FJZcDNwHuATcAySUsiYk1OtVeAq4G/6bT5AeATEfGCpEnAk5IejIhd6frPR8S9xYo9VybjMQ4zs1xFSxzAfGBdRLwEIOlu4BKgPXFExPp0XYf/6SPi+ZzlLZK2AvXALgZZcsThxGFm1qaYXVWTgY05zzelZQWRNB8YAbyYU/y1tAvr25Iqe9hukaTlkpZv27at0Jdtl8k4cZiZ5RrSg+OSJgI/Ba6JiLajkhuAE4HTgXHAF7rbNiJujYh5ETGvvr6+3zGUZeSuKjOzHMVMHJuBqTnPp6RleZE0GvgV8LcR8XhbeUS8GolG4IckXWJF464qM7OOipk4lgHHS5ohaQSwEFiSz4Zp/fuAn3QeBE+PQpAk4FJg1YBG3UnGRxxmZh0ULXFERAtwHfAg8CxwT0SslnSTpIsBJJ0uaRNwOfB9SavTzT8CnAtc3c1pt3dIegZ4BpgAfLVYbYDk9rFZn45rZtaumGdVERFLgaWdym7MWV5G0oXVebt/Af6lh32+a4DD7FWZfAGgmVmuIT04PhRkMvKUI2ZmOZw4+uApR8zMOnLi6IPPqjIz68iJow8+q8rMrCMnjj74iMPMrCMnjj4kU46UOgozs6Gjz8Qh6R8kjZZUIek/JG2T9LHBCG4oKPPsuGZmHeRzxPHeiNgD/DmwHjgO+HwxgxpKMvIYh5lZrnwSR9tFgu8H/jUidhcxniEn4zEOM7MO8rly/N8kPQccBD4tqR5oKG5YQ4dnxzUz66jPI46IWAy8A5gXEc3AfpIbMg0LPqvKzKyjfAbHLweaI6JV0v8gmUNqUtEjGyIyGU9yaGaWK58xji9FxF5JZwPvBm4DbiluWEOHpxwxM+son8TRmv58P3BrRPyK5Fauw4IHx83MOsoncWyW9H3gCmBpeo/vYXPhoAfHzcw6yicBfITkZkzvi4hdJPf5HjbXcXhw3Myso3zOqjoAvAi8T9J1wFER8e9Fj2yISKYcceIwM2uTz1lVnwXuAI5KH/8i6f/JZ+eSFkhaK2mdpMXdrD9X0lOSWiRd1mndVZJeSB9X5ZSfJumZdJ/fTe89XjQZgXuqzMwOyaer6pPAGRFxY3rb1zOBa/vaSFIZcDNwIXAS8FFJJ3Wq9gpwNXBnp23HAV8GzgDmA1+WVJeuviV9/ePTx4I82tBvPqvKzKyjfBKHOHRmFelyPv/lzwfWRcRLEdEE3E2nCwcjYn1ErAQ6XynxPuDXEbEzIt4Afg0skDQRGB0Rj0dEAD8BLs0jln7LyLeONTPLlc+UIz8EnpB0X/r8UpJrOfoyGdiY83wTyRFEPrrbdnL62NRNeReSFgGLAKZNm5bny3blIw4zs47yGRz/FnANsDN9XBMR3yl2YIcrIm6NiHkRMa++vr7f+/FZVWZmHfV4xJGOM7RZnz7a10XEzj72vRmYmvN8SlqWj83AeZ22fTQtn9LPffZLJuOuKjOzXL11VT0JBIfGM9q+PZUuH9vHvpcBx0uaQfLlvhD4izzjehD4+5wB8fcCN0TETkl7JJ0JPAF8AvjHPPfZL2VyV5WZWa4eE0dEzDicHUdES3rdx4NAGXB7RKyWdBOwPCKWSDoduA+oAz4g6e8iYlaaIP4nSfIBuCnnCOe/AD8CqoEH0kfR+NaxZmYd5TM43m8RsRRY2qnsxpzlZXTsesqtdztwezfly4GTBzbSnvnWsWZmHQ2bOaf6Ze9rjG/a7MFxM7McThy9+eWnuXz93/mIw8wsR16JQ9LZkq5Jl+vTAe8jX/U4alp3+6wqM7Mc+cxV9WXgC8ANaVEFyV0Aj3w146hu2eOzqszMcuRzxPFB4GKSe40TEVuAUcUMasioHkd1616Ube27rpnZMJFP4mhK54UKAEm1xQ1pCKlJroEcGftKHIiZ2dCRT+K4J70D4FhJ1wIPAT8oblhDRHWSOEbHnhIHYmY2dPR5HUdEfFPSe4A9wAnAjRHx66JHNhRUJxeuj2Uf2WyQyRT11h9mZm8KfSaOtGvq4Yj4taQTgBMkVUREc/HDK7GaNHFoH02tWaoyZSUOyMys9PLpqvotUClpMvD/Ax8nmfLjyJd2VdVpH/sbW0ocjJnZ0JDXjZzS+45/CLglIi4HZhU3rCEiHRwfyz72N/rMKjMzyDNxSPoz4ErgV2nZ8OizqRxNVuXUaS/7fMRhZgbklzg+R3Lx333p7LbHAo8UN6whQqKlcgx17HPiMDNL5XNW1W+A3+Q8fwm4vphBDSWtVXWM3e8xDjOzNvmcVTUP+CIwPbd+RJxavLCGkKo66tjHNicOMzMgv/tx3AF8HngGGHa3NFLNOMbqNdY7cZiZAfkljm0RsaTokQxRmdrxPh3XzCxHPoPjX5b0vyV9VNKH2h757FzSAklrJa2TtLib9ZWSfpauf0LS9LT8Skkrch5ZSbPTdY+m+2xbd1QB7S1Y+cjxjGUfexucOMzMIL8jjmuAE0mmU2/rqgrgF71tJKkMuBl4D7AJWCZpSUSsyan2SeCNiDhO0kLgG8AVEXEHSRcZkk4BfhkRK3K2uzK9hWzRZarHUqVmGg7uH4yXMzMb8vJJHKdHxAn92Pd8YF16FhaS7gYuAXITxyXAV9Lle4F/kqR0Nt42HwXu7sfrD4wRyWTAzQc9Q66ZGeTXVfUHSSf1Y9+TgY05zzelZd3WiYgWYDcwvlOdK4C7OpX9MO2m+pKkbmcelLRI0nJJy7dt29aP8FNtiaPBicPMDPJLHGcCK9JxhZWSnpG0stiBAUg6AzgQEatyiq+MiFOAc9LHx7vbNiJujYh5ETGvvr6+/0FU1ADQ6sRhZgbk11W1oJ/73gxMzXk+JS3rrs4mSeXAGGBHzvqFdDraiIjN6c+9ku4k6RL7ST9j7Ft6xJFtcuIwM4P8rhzf0M99LwOOlzSDJEEsBP6iU50lwFXAY8BlJNO3t91pMAN8hOSogrSsHBgbEdslVQB/TnJjqeJpSxyNB4r6MmZmbxb5HHH0S0S0SLoOeJBkUsTb07mubgKWp9eG3Ab8VNI6YCdJcmlzLrCxbXA9VQk8mCaNMgbjboQVSeJQs484zMygiIkDICKWAks7ld2Ys9wAXN7Dto+SjK/klu0HThvwQHuTHnGo6eCgvqyZ2VCVz+D48DYiGRzPNPs6DjMzcOLoW9pVNSIaaGoZdlN1mZl14cTRl7SrqoZGz1dlZoYTR9/KKwky1KjBN3MyM8OJo28SreXV1NDoxGFmhhNHXloraql24jAzA5w48hIVNdS6q8rMDHDiyE9FDdUeHDczA5w48qLKkckYh2/mZGbmxJGPzIhad1WZmaWcOPJQVunBcTOzNk4cechUjqRWHuMwMwMnjvyMqKFWjexrbC11JGZmJefEkY+KGqrxGIeZGThx5GfESKpo4kBDY6kjMTMrOSeOfKRTqzcf9NTqZmZOHPlIZ8htbXTiMDMrauKQtEDSWknrJC3uZn2lpJ+l65+QND0tny7poKQV6eN7OducJumZdJvvSlIx2wC035Mjmnz7WDOzoiUOSWXAzcCFwEnARyWd1KnaJ4E3IuI44NvAN3LWvRgRs9PHp3LKbwGuBY5PHwuK1YZ2aVdV1kccZmZFPeKYD6yLiJciogm4G7ikU51LgB+ny/cCF/R2BCFpIjA6Ih6PiAB+Alw68KF30n7fcScOM7NiJo7JwMac55vSsm7rREQLsBsYn66bIelPkn4j6Zyc+pv62CcAkhZJWi5p+bZt2w6vJVV1AFRn99Lc6tvHmtnwNlQHx18FpkXEHOCvgTsljS5kBxFxa0TMi4h59fX1hxdNTZI4xmmvrx43s2GvmIljMzA15/mUtKzbOpLKgTHAjohojIgdABHxJPAi8La0/pQ+9jnwapKDoLHsY69nyDWzYa6YiWMZcLykGZJGAAuBJZ3qLAGuSpcvAx6OiJBUnw6uI+lYkkHwlyLiVWCPpDPTsZBPAPcXsQ2JytFkVZ4ccTQ5cZjZ8FZerB1HRIuk64AHgTLg9ohYLekmYHlELAFuA34qaR2wkyS5AJwL3CSpGcgCn4qInem6/wL8CKgGHkgfxSXRXFlHXbO7qszMipY4ACJiKbC0U9mNOcsNwOXdbPdz4Oc97HM5cPLARtq3bFUddfvdVWVmNlQHx4ecqB5Hnfay3zPkmtkw58SRr9rxjGMv+xqbSx2JmVlJOXHkqax2PGO1111VZjbsOXHkacSoeurYx459DaUOxcyspJw48qTa8ZQry66d20sdiplZSTlx5Kt6HAAHdm0tcSBmZqXlxJGv9Orxxj0+4jCz4c2JI19p4sju3042GyUOxsysdJw48pVOdDg69rDzQFOJgzEzKx0njnzVTADgKN7g1V0+s8rMhi8njnxVjaah7gTOyaxiy+6DpY7GzKxknDgKkD3+fZyeeY4d231mlZkNX04cBaia9X7KlaVm46OlDsXMrGScOAqQmXo6uxjFxK2/L3UoZmYl48RRiEwZmyvfyugDG0odiZlZyThxFKh55GTGNb9Oq6/lMLNhyomjQBXjplHPLjZu21XqUMzMSqKoiUPSAklrJa2TtLib9ZWSfpauf0LS9LT8PZKelPRM+vNdOds8mu5zRfo4qpht6GzUMceSUbBx/brBfFkzsyGjaIlDUhlwM3AhcBLwUUkndar2SeCNiDgO+DbwjbR8O/CBiDgFuAr4aaftroyI2eljUM+NrZ/y1iTAzU4cZjY8FfOIYz6wLiJeiogm4G7gkk51LgF+nC7fC1wgSRHxp4jYkpavBqolVRYx1rxVT5gOwP6t60sah5lZqRQzcUwGNuY835SWdVsnIlqA3cD4TnU+DDwVEY05ZT9Mu6m+JEndvbikRZKWS1q+bdu2w2lHR6OTJmR3beyjopnZkWlID45LmkXSffVXOcVXpl1Y56SPj3e3bUTcGhHzImJefX39wAVVUcW+ivFUH9hCS2t24PZrZvYmUczEsRmYmvN8SlrWbR1J5cAYYEf6fApwH/CJiHixbYOI2Jz+3AvcSdIlNqiaaidxdGxn/Y4Dg/3SZmYlV8zEsQw4XtIMSSOAhcCSTnWWkAx+A1wGPBwRIWks8CtgcUT8Z1tlSeWSJqTLFcCfA6uK2IZuldVNY7K28/zrewf7pc3MSq5oiSMds7gOeBB4FrgnIlZLuknSxWm124DxktYBfw20nbJ7HXAccGOn024rgQclrQRWkByx/KBYbehJ7VHTk8Tx2p7Bfmkzs5IrL+bOI2IpsLRT2Y05yw3A5d1s91Xgqz3s9rSBjLE/yse9hXI1s2XLRuCEUodjZjaohvTg+JA1ZgoA+3xKrpkNQ04c/TEmGfPXro00trSWOBgzs8HlxNEf6RHHMWznFZ9ZZWbDjBNHf1TX0VpewyTt4JWdThxmNrw4cfSHRIyZymRtZ4OPOMxsmHHi6KeyuqlMzfiIw8yGHyeOftKYqUzJbHfiMLNhx4mjv8ZMYUzs4bXtO0sdiZnZoHLi6K8JxwMwZtcasr6NrJkNI04c/XXs+bSqggt4gtf3NpQ6GjOzQePE0V9Vo9k18WwWlC3jle37Sx2NmdmgceI4DJlZFzNF29m69vFSh2JmNmicOA5D3exkkt+mFx4ucSRmZoPHieNw1E5ga+VbGL/zTzS1+G6AZjY8OHEcpsZJZzCH5/jThh2lDsXMbFA4cRymCSe9kzE6wJPLHyt1KGZmg8KJ4zBVv/UsALY/8xDP+Y6AZr3yNU9HhqImDkkLJK2VtE7S4m7WV0r6Wbr+CUnTc9bdkJavlfS+fPc56Oqm0zphJovL7+DRH3yB+/5zJQ3NvkfHgGptgfAXzpvdjn2NnPMPj3Db718udSh2mIp261hJZcDNwHuATcAySYJjWB4AAAwPSURBVEsiYk1OtU8Cb0TEcZIWAt8ArpB0ErAQmAVMAh6S9LZ0m772Obgkyq75FXt/9ld86pU74dd3sv3fx/ByxST21kylZfQ0GDeDGDONEbVjqRo5ltpRY6gdOZKaqirKykeQyWTISGRE8jOj0rSlpYn4t/8Krz6NPnonjJ0GLY0c/N0/0tKwj5EXfB6NqO24TQS0NkF5Zff7jKBp3aM0MYIR089kREVZfrG8vgbW/56W+plkfnEtDUe9ncZL/jd1Y0b1vl02S3M2yAIjyjLsbWxhVGU5Ug+/01dX0tKwh90TTqOutirv3/0b+5v4yWMbmFJXzYWnHEPNiMP4U8q2QmShrKLb1U0tWUaU9/w/XkSw9rU9rH1tD6NrKnnHW8dTWZ7n73kQ/dNDz1K9+wVueXAXF51yDBPHVJc6pHbZbCDR9XPS2gxrH6C5rJqGae9kVPWIgvYbLU1s3tPMqKoRjKnp/v3toOkAKAMVVXntv7k1y4GmVkZVlg/q94aiSP/JSfoz4CsR8b70+Q0AEfG/cuo8mNZ5TFI58BpQDyzOrdtWL92s1312Z968ebF8+fKBa1wP4tWVbPzjL9m6YS01+zcyvmkz9dkdZNT777g5ymihjFYyZBGByJIhgGgvS58r+Qmi68dEINrXR1oj2Y/a6wRCObXa1lZGI+PZxYGoJEuG/aqmloOM5CAAe6OaA6pOYlMZgaiNA4xlD69rAg0kySMikr0G1KqBo0nm89oaY8mqglDbKx569dxHBS0cE1tpa+muqGWs9rMtxtCkKkJqb0dbKwAytHJUbIcI9lDLAaqJCMoyUKbkN3joVaCVDEfH9va27aealsyI9Hd76LenTr89gNY0OUWIkCjLdKzV/pno9C6FOq5TBEfHNsppYYfqaKWsvV2BKI9mRsZ+GqikQdWEMsknJbKU0UoZrVRGI1U0ArCbWvapFlTW6R3v2p62tnQt6249KKJDGZF+2ebUz/1cdXx3grJopVxZWiLDNupAmfTzfOjzntTu/GntuJ/c59214dD71LHeobp0iJMI2r4HM6LDfipooZImIPn8Nqsyua0CIpuz5w5vc/oyldHIUWwnAvZTzUFV06Aq6Fw/VR7J576MLPuoZY9GEXSsmvymspSl3wpkWwmghTKyKoP07zL5G01iK//YvUw+dmbXF8yDpCcjYl6XWPu1t/xMBjbmPN8EnNFTnYhokbQbGJ+WP95p28npcl/7BEDSImARwLRp0/rXggJp4qlMu+RUcl+tufEAO7a8SNOODTTs30PTgd20HNxLS+N+WpqbUbYJZVvIZFsgWpMPcGRRZInIpt/62faHyBIBQbT33kSQfvA7JgNI/tjp9AejiPYvsNyvEyQeGXc2DXVv49SNd9CSDRpiBNsmnkd1TS31G/6NaG0msi1kW5MYmzJV7K2YwPjmVymPZtq+FyVRJrEn4E8T3sHI8ixjd6zgQFNLp3SRNODQH3bQqnJWVU5h47izePve3/LyWy5jSsPzjNv8MPsONhNtdePQl1wAKMPz5fVUV42gtnUvatpHZUU5+5uztGRpT8DZ9HdWQTP/WXUC2dp6ZjY/S0vjAVoaDxCRPRRdTpJqE4jyDBx31EiaW1rZtreBA40tHX7PyeKh9yMOFUJ0/OJaV/EOmlXJ2JZtnVJoQFklmZqxRNNBaNoL2SxZlZFVOZEpSxJ4eRWjRo1m4phqGvbuYOe212ltbe0Qd+d0EBKkSS+3XW11yEnuuZ+Ptv2VZTKUl5XR1Jrt9I9K2jLlvFakv7OKEcybO4/tG9aw87UNtGazZLPZ9n+Nks935398IieunE+3cp9314Z0Xfuq7tJK+g+HRG1VcjTQ3Bo0Z4OWbPqvmTK8NHIuR1fs59h9T7HvYBPtSbP9c5jtEIOU/FOXzVSwpmoSE2oraD24h6aDexjR2pD+Trr+MxkST1e8lxZVMLp1JzWte3PWHnofsypLE22G6soKakaU0dLSTGtzM82tLUQ2m6a1IBNZplYN/JFdMRNHSUXErcCtkBxxlCqOisoa6mecAjNOKVUIBTm9fenCbtZeNniBtLuc5N+ddwLXDvje5w/APuoHYB8DaXLfVUqq9gx4S6mDKMA7Sx3AEFTMwfHNwNSc51PSsm7rpF1VY4AdvWybzz7NzKyIipk4lgHHS5ohaQTJYPeSTnWWAFely5cBD0dyDLcEWJiedTUDOB74Y577NDOzIipaV1U6ZnEd8CBQBtweEasl3QQsj4glwG3ATyWtA3aSJALSevcAa4AW4DMR0QrQ3T6L1QYzM+uqaGdVDSWDdVaVmdmRpKezqnzluJmZFcSJw8zMCuLEYWZmBXHiMDOzggyLwXFJ24AN/dx8ArB9AMN5M3Cbh4fh2GYYnu3ub5vfEhFdrnEdFonjcEha3t1ZBUcyt3l4GI5thuHZ7oFus7uqzMysIE4cZmZWECeOvt1a6gBKwG0eHoZjm2F4tntA2+wxDjMzK4iPOMzMrCBOHGZmVhAnjl5IWiBpraR1khaXOp5ikbRe0jOSVkhanpaNk/RrSS+kP+tKHefhkHS7pK2SVuWUddtGJb6bvu8rJc0tXeT910ObvyJpc/per5B0Uc66G9I2r5X0vtJEfXgkTZX0iKQ1klZL+mxafsS+1720uXjvdaT32/Wj44Nk2vYXgWOBEcDTwEmljqtIbV0PTOhU9g/A4nR5MfCNUsd5mG08F5gLrOqrjcBFwAMk9+s8E3ii1PEPYJu/AvxNN3VPSj/jlcCM9LNfVuo29KPNE4G56fIo4Pm0bUfse91Lm4v2XvuIo2fzgXUR8VJENAF3A5eUOKbBdAnw43T5x8ClJYzlsEXEb0nu+ZKrpzZeAvwkEo8DYyVNHJxIB04Pbe7JJcDdEdEYES8D6xiYO+sOqoh4NSKeSpf3As+S3E33iH2ve2lzTw77vXbi6NlkYGPO800M/ds591cA/y7pSUmL0rKjI+LVdPk14OjShFZUPbXxSH/vr0u7ZW7P6YI84tosaTowB3iCYfJed2ozFOm9duIwgLMjYi5wIfAZSefmrozk+PaIPm97OLQxdQvwVmA28Crw/5U2nOKQNBL4OfC5iNiTu+5Ifa+7aXPR3msnjp5tBqbmPJ+Slh1xImJz+nMrcB/JYevrbYfs6c+tpYuwaHpq4xH73kfE6xHRGhFZ4Acc6qI4YtosqYLkC/SOiPhFWnxEv9fdtbmY77UTR8+WAcdLmiFpBMn90JeUOKYBJ6lW0qi2ZeC9wCqStl6VVrsKuL80ERZVT21cAnwiPePmTGB3TjfHm1qn/vsPkrzXkLR5oaRKSTOA44E/DnZ8h0uSgNuAZyPiWzmrjtj3uqc2F/W9LvUZAUP5QXLGxfMkZx38banjKVIbjyU5w+JpYHVbO4HxwH8ALwAPAeNKHethtvMuksP1ZpI+3U/21EaSM2xuTt/3Z4B5pY5/ANv807RNK9MvkIk59f82bfNa4MJSx9/PNp9N0g21EliRPi46kt/rXtpctPfaU46YmVlB3FVlZmYFceIwM7OCOHGYmVlBnDjMzKwgThxmZlYQJw6zIU7SeZL+rdRxmLVx4jAzs4I4cZgNEEkfk/TH9N4H35dUJmmfpG+n90n4D0n1ad3Zkh5PJ6C7L+f+EMdJekjS05KekvTWdPcjJd0r6TlJd6RXC5uVhBOH2QCQNBO4AjgrImYDrcCVQC2wPCJmAb8Bvpxu8hPgCxFxKsnVvW3ldwA3R8TbgXeQXPkNyYynnyO5l8KxwFlFb5RZD8pLHYDZEeIC4DRgWXowUE0ykV4W+Fla51+AX0gaA4yNiN+k5T8G/jWdM2xyRNwHEBENAOn+/hgRm9LnK4DpwO+L3yyzrpw4zAaGgB9HxA0dCqUvdarX3zl+GnOWW/HfrpWQu6rMBsZ/AJdJOgra73H9FpK/scvSOn8B/D4idgNvSDonLf848JtI7t62SdKl6T4qJdUMaivM8uD/WswGQESskfQ/SO6kmCGZkfYzwH5gfrpuK8k4CCRTe38vTQwvAdek5R8Hvi/ppnQflw9iM8zy4tlxzYpI0r6IGFnqOMwGkruqzMysID7iMDOzgviIw8zMCuLEYWZmBXHiMDOzgjhxmJlZQZw4zMysIP8XqNqvpEMaAEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['val_mse'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('mse loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
